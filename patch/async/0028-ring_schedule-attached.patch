From 336dfcf1178b7c3242f3053ae3e9024df6537765 Mon Sep 17 00:00:00 2001
From: andre <12485443-Andre_HJR@users.noreply.gitlab.com>
Date: Sat, 18 Feb 2023 08:47:51 -0500
Subject: [PATCH 28/80] ring_schedule attached !

---
 Cargo.toml                                    |   6 +-
 application/ring_scheduler/Cargo.toml         |  13 +
 .../ring_scheduler/src/algorithm/mod.rs       |  32 ++
 .../ring_scheduler/src/algorithm/ring_fifo.rs | 132 +++++++++
 application/ring_scheduler/src/console.rs     |  33 +++
 application/ring_scheduler/src/lib.rs         | 129 +++++++++
 application/ring_scheduler/src/linker.ld      |  44 +++
 application/ring_scheduler/src/mm.rs          |  14 +
 application/ring_scheduler/src/syscall.rs     |  83 ++++++
 application/ring_scheduler/src/task.rs        | 274 ++++++++++++++++++
 10 files changed, 759 insertions(+), 1 deletion(-)
 create mode 100644 application/ring_scheduler/Cargo.toml
 create mode 100644 application/ring_scheduler/src/algorithm/mod.rs
 create mode 100644 application/ring_scheduler/src/algorithm/ring_fifo.rs
 create mode 100644 application/ring_scheduler/src/console.rs
 create mode 100644 application/ring_scheduler/src/lib.rs
 create mode 100644 application/ring_scheduler/src/linker.ld
 create mode 100644 application/ring_scheduler/src/mm.rs
 create mode 100644 application/ring_scheduler/src/syscall.rs
 create mode 100644 application/ring_scheduler/src/task.rs

diff --git a/Cargo.toml b/Cargo.toml
index 06eab03..b929a8f 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -2,6 +2,7 @@
 members = [
     "application/easy-fs-fuse",
     "application/user",
+    "application/ring_scheduler",
     "asynchronous",
     "drivers",
     "easy-fs", 
@@ -34,4 +35,7 @@ exclude = [
 panic = "abort"
 
 [profile.release]
-panic = "abort"
\ No newline at end of file
+panic = "abort"
+
+[patch.crates-io]
+riscv = { git = "https://github.com/Andre-HJR/riscv.git", rev = "031d548a" }
\ No newline at end of file
diff --git a/application/ring_scheduler/Cargo.toml b/application/ring_scheduler/Cargo.toml
new file mode 100644
index 0000000..bb8ea36
--- /dev/null
+++ b/application/ring_scheduler/Cargo.toml
@@ -0,0 +1,13 @@
+[package]
+name = "ring_scheduler"
+version = "0.1.0"
+edition = "2021"
+
+# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
+
+[dependencies]
+spin = "0.7"
+riscv = "0.10.1"
+lazy_static = { version = "1", features = ["spin_no_std"] }
+r0 = "1.0"
+buddy_system_allocator = "0.6"
\ No newline at end of file
diff --git a/application/ring_scheduler/src/algorithm/mod.rs b/application/ring_scheduler/src/algorithm/mod.rs
new file mode 100644
index 0000000..add766c
--- /dev/null
+++ b/application/ring_scheduler/src/algorithm/mod.rs
@@ -0,0 +1,32 @@
+//! 调度算法这这里实现
+
+mod ring_fifo;
+pub use ring_fifo::RingFifoScheduler;
+
+/// 调度器实例需要实现的 Trait
+pub trait Scheduler<T: Clone + PartialEq> {
+    /// 优先级的类型
+    type Priority;
+    /// 向调度器中添加一个任务，成功返回 None，不成功返回 Some(T)
+    fn add_task(&mut self, task: T) -> Option<T>;
+    /// 获取下一个任务的不可变引用，但不弹出任务
+    fn peek_next_task(&self) -> Option<&T>;
+    /// 获取下一个任务的可变引用，但不弹出任务
+    fn peek_next_task_mut(&mut self) -> Option<&mut T>;
+    /// 弹出下一个时间段应当执行的任务
+    fn next_task(&mut self) -> Option<T>;
+    /// 获取正在运行的任务，中断发生时，将保存这个任务的上下文
+    fn current_task(&self) -> Option<T>;
+    /// 移除一个任务
+    fn remove_task(&mut self, task: &T);
+    /// 设置任务的优先级
+    fn set_priority(&mut self, task: T, priority: Self::Priority);
+    /// 返回调度队列的总长度
+    /// 如果有队列，则返回 Some，否则返回 None
+    ///
+    /// 目前这里是实现上的需要，后面需要移除这个方法
+    /// 因为具体调度器实现里面可能没有队列，这个不是调度器的共性
+    fn queue_len(&self) -> Option<usize> {
+        None
+    }
+}
diff --git a/application/ring_scheduler/src/algorithm/ring_fifo.rs b/application/ring_scheduler/src/algorithm/ring_fifo.rs
new file mode 100644
index 0000000..b14dd5a
--- /dev/null
+++ b/application/ring_scheduler/src/algorithm/ring_fifo.rs
@@ -0,0 +1,132 @@
+//! 循环先进先出队列调度器实现
+
+use super::Scheduler;
+use core::mem::MaybeUninit;
+use core::ptr;
+
+/// 先进先出轮转任务调度器
+pub struct RingFifoScheduler<T, const N: usize> {
+    ring: RingQueue<T, N>,
+    current: Option<T>,
+}
+
+impl<T, const N: usize> RingFifoScheduler<T, N> {
+    /// 创建一个空的调度器
+    pub const fn new() -> Self {
+        Self {
+            ring: RingQueue::new(),
+            current: None,
+        }
+    }
+}
+
+impl<T: Clone + PartialEq, const N: usize> Scheduler<T> for RingFifoScheduler<T, N> {
+    type Priority = ();
+    /// 添加任务
+    fn add_task(&mut self, task: T) -> Option<T> {
+        // 加入环形队列
+        let ans = self.ring.push_back(task);
+        // 直接返回self.ring.push_back也可以
+        if let Some(t) = ans {
+            // 如果满了，退出
+            return Some(t);
+        }
+        None
+    }
+    /// 取出下一个任务，成功返回 Some(T)
+    fn next_task(&mut self) -> Option<T> {
+        // 从头部取出
+        let ans = self.ring.pop_front();
+        self.current = ans.clone();
+        ans
+    }
+    /// 拿出下一个任务的不可变引用，不弹出
+    fn peek_next_task(&self) -> Option<&T> {
+        self.ring.front()
+    }
+    /// 拿出下一个任务的可变引用，不弹出
+    fn peek_next_task_mut(&mut self) -> Option<&mut T> {
+        self.ring.front_mut()
+    }
+    /// 获取当前任务
+    fn current_task(&self) -> Option<T> {
+        self.current.clone()
+    }
+    /// 移除一个特定的任务
+    fn remove_task(&mut self, task: &T) {
+        // 移除相应的线程并且确认恰移除一个线程
+        drop(task);
+        todo!("还没做")
+    }
+    /// 设置任务优先级
+    fn set_priority(&mut self, _task: T, _prio: ()) {}
+    /// 当前调度器的任务数，如果是队列实现则返回 Some(T)
+    fn queue_len(&self) -> Option<usize> {
+        Some(self.ring.len())
+    }
+}
+
+pub struct RingQueue<T, const N: usize> {
+    elem: [MaybeUninit<T>; N],
+    front: usize,
+    tail: usize,
+}
+
+impl<T, const N: usize> RingQueue<T, N> {
+    pub const fn new() -> Self {
+        Self {
+            elem: MaybeUninit::uninit_array(),
+            front: 0,
+            tail: 0,
+        }
+    }
+    pub const fn len(&self) -> usize {
+        self.tail.wrapping_sub(self.front) % N
+    }
+    pub const fn is_empty(&self) -> bool {
+        self.tail == self.front
+    }
+    #[inline]
+    fn is_full(&self) -> bool {
+        self.len() == N - 1
+    }
+    // if push failed, value T is returned
+    pub fn push_back(&mut self, value: T) -> Option<T> {
+        if self.is_full() {
+            return Some(value);
+        }
+        unsafe { *self.elem[self.tail].as_mut_ptr() = value };
+        self.tail = self.tail.wrapping_add(1);
+        // '>' -> '>='
+        if self.tail >= N || self.tail == 0 {
+            self.tail = self.tail.wrapping_sub(N);
+        }
+        None // success
+    }
+    pub fn pop_front(&mut self) -> Option<T> {
+        if self.is_empty() {
+            return None;
+        }
+        let value = unsafe { ptr::read(self.elem[self.front].as_ptr()) };
+        self.front = self.front.wrapping_add(1); // assured non empty
+                                                 // '>' -> '>='
+        if self.front >= N || self.front == 0 {
+            self.front = self.front.wrapping_sub(N);
+        }
+        Some(value)
+    }
+    pub fn front(&self) -> Option<&T> {
+        if self.is_empty() {
+            None
+        } else {
+            Some(unsafe { &*self.elem[self.front].as_ptr() })
+        }
+    }
+    pub fn front_mut(&mut self) -> Option<&mut T> {
+        if self.is_empty() {
+            None
+        } else {
+            Some(unsafe { &mut *self.elem[self.front].as_mut_ptr() })
+        }
+    }
+}
diff --git a/application/ring_scheduler/src/console.rs b/application/ring_scheduler/src/console.rs
new file mode 100644
index 0000000..71b90b8
--- /dev/null
+++ b/application/ring_scheduler/src/console.rs
@@ -0,0 +1,33 @@
+//! 控制台输出，用于调试
+use crate::syscall;
+use core::fmt::{self, Write};
+
+struct Stdout;
+
+static STDOUT_LOCK: spin::Mutex<()> = spin::Mutex::new(());
+
+impl Write for Stdout {
+    fn write_str(&mut self, s: &str) -> fmt::Result {
+        STDOUT_LOCK.lock();
+        syscall::sys_test_write(s.as_bytes());
+        Ok(())
+    }
+}
+
+pub fn print(args: fmt::Arguments) {
+    Stdout.write_fmt(args).unwrap();
+}
+
+#[macro_export]
+macro_rules! print {
+    ($fmt: literal $(, $($arg: tt)+)?) => {
+        $crate::console::print(format_args!($fmt $(, $($arg)+)?));
+    }
+}
+
+#[macro_export]
+macro_rules! println {
+    ($fmt: literal $(, $($arg: tt)+)?) => {
+        $crate::console::print(format_args!(concat!($fmt, "\n") $(, $($arg)+)?));
+    }
+}
diff --git a/application/ring_scheduler/src/lib.rs b/application/ring_scheduler/src/lib.rs
new file mode 100644
index 0000000..3dbf33a
--- /dev/null
+++ b/application/ring_scheduler/src/lib.rs
@@ -0,0 +1,129 @@
+//! 以二进制包的形式编译
+//!
+//! 使用方法：将本项目编译出的二进制文件直接烧录到内存中，
+//! 然后在内核和用户代码中以基地址实例化共享调度器。
+//!
+//! 基地址在链接脚本`src/linker-xxx.ld`中指定。同时在烧写的时候也需要指定。
+//!
+//! 实例化方法：请参考`tornado-kernel/src/task/shared.rs`
+#![no_std]
+#![no_main]
+#![feature(panic_info_message)]
+#![feature(alloc_error_handler)]
+#![feature(maybe_uninit_uninit_array)]
+#![feature(naked_functions)]
+#![feature(const_maybe_uninit_uninit_array)]
+
+extern crate alloc;
+
+#[macro_use]
+mod console;
+mod algorithm;
+mod mm;
+mod syscall;
+mod task;
+
+use crate::{
+    mm::AddressSpaceId,
+    task::{
+        shared_add_task, shared_delete_task, shared_peek_task, shared_set_task_state,
+        SharedScheduler, TaskRepr, TaskResult, TaskState, SHARED_SCHEDULER,
+    },
+};
+use buddy_system_allocator::LockedHeap;
+use core::{mem::MaybeUninit, ptr::NonNull};
+
+#[global_allocator]
+static HEAP: LockedHeap = LockedHeap::empty();
+
+const HEAP_SIZE: usize = 128 * 1024;
+static HEAP_MEMORY: MaybeUninit<[u8; HEAP_SIZE]> = core::mem::MaybeUninit::uninit();
+
+#[cfg_attr(not(test), panic_handler)]
+pub fn panic_handler(panic_info: &core::panic::PanicInfo) -> ! {
+    let err = panic_info.message().unwrap().as_str();
+    if let Some(location) = panic_info.location() {
+        syscall::sys_panic(
+            Some(location.file()),
+            location.line(),
+            location.column(),
+            err,
+        );
+    } else {
+        syscall::sys_panic(None, 0, 0, err);
+    }
+    // println!("[shared scheduler] panic: {:?}", panic_info);
+    unreachable!()
+}
+
+// todo: 未来尽量使用有Allocator的new_in函数，这样能处理内存不足的问题
+#[cfg_attr(not(test), alloc_error_handler)]
+pub fn handle_alloc_error(layout: core::alloc::Layout) -> ! {
+    println!("[shared scheduler] alloc error, layout = {:?}", layout);
+    panic!("shared scheduler alloc error: {:?}", layout)
+}
+
+/// 共享调度器虚函数表
+#[link_section = ".meta"] // 虚函数表只读
+#[no_mangle]
+pub static SHARED_RAW_TABLE: (
+    &'static u8,                        // 共享调度器编译时的基地址
+    unsafe extern "C" fn() -> PageList, // 初始化函数，执行完之后，内核将函数指针置空
+    &'static SharedScheduler,           // 共享调度器的地址
+    unsafe extern "C" fn(NonNull<()>, usize, AddressSpaceId, TaskRepr) -> bool, // 添加任务
+    unsafe extern "C" fn(NonNull<()>, extern "C" fn(AddressSpaceId) -> bool) -> TaskResult, // 弹出任务引用
+    unsafe extern "C" fn(NonNull<()>, TaskRepr) -> bool, // 删除任务
+    unsafe extern "C" fn(NonNull<()>, TaskRepr, TaskState), // 改变任务的状态
+) = (
+    unsafe { &payload_compiled_start },
+    init_payload_environment,
+    &SHARED_SCHEDULER,
+    shared_add_task,
+    shared_peek_task,
+    shared_delete_task,
+    shared_set_task_state,
+);
+
+#[allow(non_upper_case_globals)]
+extern "C" {
+    // 共享调度器编译时的起始地址，可用于内核加载时计算偏移量
+    static payload_compiled_start: u8;
+    // 每个页的开始都对齐到4K，结束并无对齐要求，结束位置应当向上取整到4K
+    static srodata_page: u8;
+    static erodata_page: u8;
+    static sdata_page: u8;
+    static edata_page: u8;
+    static stext_page: u8;
+    static etext_page: u8;
+    // 都是u32类型，将会由r0::zero_bss每次写入一个32位零内存来初始化
+    // 对应链接器脚本中的“ebss = ALIGN(4)”等等
+    static mut sbss: u32;
+    static mut ebss: u32;
+}
+
+/// 初始化共享调度器环境，只能由内核运行，只能运行一次
+unsafe extern "C" fn init_payload_environment() -> PageList {
+    // 初始化零初始段，每次写入一个u32类型的零内存
+    r0::zero_bss(&mut sbss, &mut ebss);
+    // 初始化堆
+    let heap_start = HEAP_MEMORY.as_ptr() as usize;
+    HEAP.lock().init(heap_start, HEAP_SIZE);
+    // 返回一个表，表示本共享载荷应当保护的地址范围
+    PageList {
+        rodata: [&srodata_page, &erodata_page], // 只读
+        data: [&sdata_page, &edata_page],       // 读+写
+        text: [&stext_page, &etext_page],       // 只运行
+    }
+}
+
+/// 共享调度器各个段的范围，方便内存管理的权限设置
+///
+/// 有虚拟内存，用特殊的链接器脚本，以确保对齐到4K，如果没有虚拟内存，可以使用更低的对齐方法
+#[repr(C)]
+pub struct PageList {
+    // 这里的&'static u8指向的值并不重要，它表示的地址比较重要
+    rodata: [&'static u8; 2], // 只读数据段
+    data: [&'static u8; 2],   // 数据段
+    text: [&'static u8; 2],   // 代码段
+}
+
diff --git a/application/ring_scheduler/src/linker.ld b/application/ring_scheduler/src/linker.ld
new file mode 100644
index 0000000..f0d59e5
--- /dev/null
+++ b/application/ring_scheduler/src/linker.ld
@@ -0,0 +1,44 @@
+/* RISC-V架构，4K页系统，共享调度器链接脚本 */
+
+OUTPUT_ARCH(riscv)
+ENTRY(SHARED_RAW_TABLE) /* Hack: keep raw table at entry address */
+BASE_ADDRESS = 0x86000000;
+
+SECTIONS
+{
+    . = BASE_ADDRESS;
+    payload_compiled_start = .;
+
+    .rodata : ALIGN(4K) {
+        srodata_page = .;
+        *(.meta) /* 元数据放在最开头 */
+        *(.rodata .rodata.*)
+        erodata_page = .;
+    }
+
+    . = ALIGN(4K);
+    .data : {
+        sdata_page = .;
+        *(.sdata .sdata.* .sdata2 .sdata2.*);
+        *(.data .data.*)
+    }
+
+    .bss (NOLOAD) : ALIGN(4) {
+        sbss = .;
+        *(.sbss .bss .bss.*)
+        ebss = ALIGN(4);
+    }
+    edata_page = .;
+
+    .text : ALIGN(4K) {
+        stext_page = .;
+        *(.text.entry)
+        *(.text .text.*)
+        etext_page = .;
+    }
+
+    /DISCARD/ : {
+        *(.eh_frame)
+        *(.debug*)
+    }
+}
diff --git a/application/ring_scheduler/src/mm.rs b/application/ring_scheduler/src/mm.rs
new file mode 100644
index 0000000..48383b0
--- /dev/null
+++ b/application/ring_scheduler/src/mm.rs
@@ -0,0 +1,14 @@
+//! 内存相关
+/// 地址空间编号
+///
+/// 内核地址空间编号为0，用户地址空间编号从1开始增长
+#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]
+#[repr(C)]
+pub struct AddressSpaceId(u16); // in Sv39, [0, 2^16)
+
+impl AddressSpaceId {
+    /// 地址空间编号转为[`usize`]
+    pub(crate) fn into_inner(self) -> usize {
+        self.0 as usize
+    }
+}
diff --git a/application/ring_scheduler/src/syscall.rs b/application/ring_scheduler/src/syscall.rs
new file mode 100644
index 0000000..1536b24
--- /dev/null
+++ b/application/ring_scheduler/src/syscall.rs
@@ -0,0 +1,83 @@
+//! 系统调用，用于调试
+const MODULE_TEST_INTERFACE: usize = 0x233666;
+const MODULE_PROCESS: usize = 0x114514;
+
+const FUNC_PROCESS_PANIC: usize = 0x11451419;
+
+const FUNC_TEST_WRITE: usize = 0x666233;
+
+pub fn sys_panic(file_name: Option<&str>, line: u32, col: u32, msg: Option<&str>) -> SyscallResult {
+    let (f_buf, f_len) = file_name
+        .map(|s| (s.as_ptr() as usize, s.len()))
+        .unwrap_or((0, 0));
+    let (m_buf, m_len) = msg
+        .map(|s| (s.as_ptr() as usize, s.len()))
+        .unwrap_or((0, 0));
+    syscall_6(
+        MODULE_PROCESS,
+        FUNC_PROCESS_PANIC,
+        [line as usize, col as usize, f_buf, f_len, m_buf, m_len],
+    )
+}
+
+pub fn sys_test_write(buf: &[u8]) -> SyscallResult {
+    syscall_3(
+        MODULE_TEST_INTERFACE,
+        FUNC_TEST_WRITE,
+        [0, buf.as_ptr() as usize, buf.len()],
+    )
+}
+
+pub struct SyscallResult {
+    pub code: usize,
+    pub extra: usize,
+}
+
+fn syscall_3(module: usize, func: usize, args: [usize; 3]) -> SyscallResult {
+    match () {
+        #[cfg(any(target_arch = "riscv32", target_arch = "riscv64"))]
+        () => {
+            let (code, extra);
+            unsafe {
+                // shared-scheduler/src/syscall.rs-COMMENT: 2022-11-06 Sun Andre :] identify the core::arch::asm
+                core::arch::asm!(
+                    "ecall",
+                    in("a0") args[0], in("a1") args[1], in("a2") args[2],
+                    in("a6") func, in("a7") module,
+                    lateout("a0") code, lateout("a1") extra,
+                )
+            };
+            SyscallResult { code, extra }
+        }
+        #[cfg(not(any(target_arch = "riscv32", target_arch = "riscv64")))]
+        () => {
+            drop((module, func, args));
+            unimplemented!("not RISC-V instruction set architecture")
+        }
+    }
+}
+
+fn syscall_6(module: usize, func: usize, args: [usize; 6]) -> SyscallResult {
+    match () {
+        #[cfg(any(target_arch = "riscv32", target_arch = "riscv64"))]
+        () => {
+            let (code, extra);
+            unsafe {
+                // shared-scheduler/src/syscall.rs-COMMENT: 2022-11-06 Sun Andre :] identify the core::arch::asm
+                core::arch::asm!(
+                    "ecall",
+                    in("a0") args[0], in("a1") args[1], in("a2") args[2],
+                    in("a3") args[3], in("a4") args[4], in("a5") args[5],
+                    in("a6") func, in("a7") module,
+                    lateout("a0") code, lateout("a1") extra,
+                )
+            };
+            SyscallResult { code, extra }
+        }
+        #[cfg(not(any(target_arch = "riscv32", target_arch = "riscv64")))]
+        () => {
+            drop((module, func, args));
+            unimplemented!("not RISC-V instruction set architecture")
+        }
+    }
+}
diff --git a/application/ring_scheduler/src/task.rs b/application/ring_scheduler/src/task.rs
new file mode 100644
index 0000000..d7d4e79
--- /dev/null
+++ b/application/ring_scheduler/src/task.rs
@@ -0,0 +1,274 @@
+//! 共享调度器的设计思路
+//!
+//! 在这个内核中，调度器和执行器是分离的。调度器只根据元数据调度，得到下一个任务是什么。
+//! 至于这个任务该如何运行，调度器不知道，需要交给执行器来解释元数据的意义，拿到异步结构之后运行。
+//!
+//! 这里的异步结构由每个地址空间规定，通常来说，它包含着一个[`Future`]，用于运行任务。
+//!
+//! 地址空间对应一套虚实地址的映射关系，它相当于传统意义上“进程”的一部分。
+//! 对地址空间来说，它规定了虚拟地址的意义，因此如果一个任务的元数据包含它的指针，只有这个地址空间能解释它。
+//! 比如共享的任务元数据包含一个指针，但只有创建这个元数据的地址空间，能理解这个元数据的意义。
+//!
+//! 在每个地址空间，都存在一个执行器。调度器运行调度算法，如果调度算法得到的任务属于当前地址空间，
+//! 那么当前空间的执行器能理解元数据的意义，就能从指针中获取到异步结构，便可运行对应的任务。
+//!
+//! 如果执行器从共享调度器中拿到的任务不属于当前地址空间，则不能理解这个任务的元数据的意义，这时候通常需要进行地址空间的切换。
+//!
+//! 每个地址空间的执行器能各自解释任务，那么异步结构的设计就因人而异，不一定局限于内核的设计。
+//! 用户运行时应当给出自己的设计，然后提供统一的指针，写到元数据中，供调度器调度。
+//! 调度器不能理解统一指针的意义，但是能理解任务所在的地址空间编号、硬件线程和优先级。通过这三个参数，
+//! 共享调度器就能完成调度任务了。
+//!
+//! **正因为地址空间是解释和运行异步任务的前提，我们认为它是异步内核不可或缺的概念。**
+//!
+//! 许多的指令集架构存在也是名为“地址空间”的优化方法，来提高页表缓存的访问效率，我们可以用它们实现软件上的地址空间。
+//! 如果具体的处理核上没有实现这种硬件优化，我们只用软件给出“地址空间”的概念，而不在硬件上利用它们。
+use crate::{
+    algorithm::{RingFifoScheduler, Scheduler},
+    mm::AddressSpaceId,
+};
+use core::ptr::NonNull;
+use spin::Mutex;
+
+/// 共享调度器返回的结果
+///
+/// note: 不应该移除，这对FFI是安全的，我们目前只考虑Rust语言的支持
+#[derive(Debug)]
+#[repr(C)]
+pub enum TaskResult {
+    /// 应当立即执行特定任务，里面是表示形式
+    ///
+    /// note: 执行器从调度器获得这个值的时候需要调用`shared_delete_task`方法释放任务,
+    /// 如果不释放任务，再次执行，还是会得到相同的任务
+    Task(TaskRepr),
+    /// 其他地址空间的任务要运行，应当提示执行器主动让出，并返回下一个地址空间的编号
+    ///
+    /// 这时候在用户态应该执行`yield`系统调用
+    /// `yield`系统调用将保存当前用户上下文，陷入内核并切换到下一个地址空间去运行
+    ShouldYield(usize),
+    /// 调度器里面没有醒着的任务，但存在睡眠任务
+    ///
+    /// note: 当调度器返回该值的次数达到阈值的时候，应当执行`kernel_check`系统调用，
+    /// 该系统调用会检查内核，适当将一些任务唤醒。
+    NoWakeTask,
+    /// 队列已空，所有任务已经结束
+    Finished,
+}
+
+/// 任务的表示形式，通常为任务结构体的指针
+#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
+#[repr(transparent)]
+pub struct TaskRepr(usize);
+
+/// 共享调度器的类型
+///
+/// 第二个泛型参数是常量泛型，设置调度器容量大小
+pub type SharedScheduler = Mutex<RingFifoScheduler<TaskMeta, 400>>;
+
+/// 全局的共享调度器
+///
+/// 放到数据段，内核或用户从这个地址里取得共享调度器
+pub static SHARED_SCHEDULER: SharedScheduler = Mutex::new(RingFifoScheduler::new());
+
+/// 共享任务的元数据
+#[derive(Debug, Clone, PartialEq, Eq, Hash)]
+#[repr(C)]
+pub struct TaskMeta {
+    /// 运行此任务的硬件线程编号
+    pub(crate) hart_id: usize,
+    /// 地址空间的编号
+    ///
+    /// 内核地址空间编号是0，用户的地址空间编号从1开始增长
+    pub(crate) address_space_id: AddressSpaceId,
+    /// 元数据指针，由所在的地址空间解释
+    task_repr: TaskRepr,
+    /// 任务当前的状态
+    pub(crate) state: TaskState,
+}
+
+/// 任务当前的状态
+#[derive(Debug, Clone, PartialEq, Eq, Hash)]
+#[repr(u8)]
+pub enum TaskState {
+    /// 就绪状态，可以被执行器执行
+    Ready = 0,
+    /// 睡眠状态
+    ///
+    /// 一个任务通常被执行器进行`poll`操作后返回`Pending`而被设置为睡眠状态，
+    /// 需要被唤醒后才能再次被执行器执行
+    Sleeping = 1,
+}
+
+/// 给共享调度器添加任务
+///
+/// * shared_scheduler: 共享调度器的[`NonNull`]指针
+/// * hard_id: 硬件线程编号
+/// * asid: 任务的地址空间编号
+/// * task_repr: 任务的指针
+///
+/// 添加任务成功返回 true,否则返回 false
+pub unsafe extern "C" fn shared_add_task(
+    shared_scheduler: NonNull<()>,
+    hart_id: usize,
+    asid: AddressSpaceId,
+    task_repr: TaskRepr,
+) -> bool {
+    let s: NonNull<SharedScheduler> = shared_scheduler.cast();
+    let handle = prepare_handle(hart_id, asid, task_repr);
+    let mut scheduler = s.as_ref().lock();
+    scheduler.add_task(handle).is_none()
+}
+
+#[inline]
+/// 用于将一些数据打包成[`TaskMeta`]
+unsafe fn prepare_handle(hart_id: usize, asid: AddressSpaceId, task_repr: TaskRepr) -> TaskMeta {
+    TaskMeta {
+        hart_id,
+        address_space_id: asid,
+        task_repr,
+        state: TaskState::Ready, // 默认为就绪状态
+    }
+}
+
+/// 从共享调度器中找到下一个任务
+///
+/// 如果拿出的任务处于睡眠状态则重新放入调度队列尾部
+///
+/// * shared_scheduler: 共享调度器的[`NonNull`]指针
+/// * should_switch: 判断是否需要进行地址空间切换的函数，由使用者给出
+///
+/// 返回一个[`TaskResult`]，执行器需要根据返回值的类型采取相应的行为
+pub unsafe extern "C" fn shared_peek_task(
+    shared_scheduler: NonNull<()>,
+    should_switch: extern "C" fn(AddressSpaceId) -> bool,
+) -> TaskResult {
+    print!(""); // 很奇怪的 bug，需要在这里输出点东西运行才会正常
+                // 得到共享调度器的引用
+    let mut s: NonNull<SharedScheduler> = shared_scheduler.cast();
+    let mut scheduler = s.as_mut().lock();
+    let mut ret_task;
+    let mut count = 0; // 计数器，防止无限循环
+    loop {
+        ret_task = scheduler.peek_next_task();
+        match ret_task {
+            Some(task) => {
+                if task.state == TaskState::Sleeping {
+                    if count >= scheduler.queue_len().unwrap() {
+                        // 已经全部遍历过一遍，没有找到醒着的任务
+                        // 返回[`TaskResult::NoWakeTask`], 提示执行器调度器里面还有睡眠任务
+                        // 如果等待时间过长，则下一次时间中断的时候切换地址空间
+                        return TaskResult::NoWakeTask;
+                    }
+                    // 睡眠状态，将当前任务放到调度队列尾部
+                    let sleep_task = scheduler.next_task().unwrap();
+                    let add_ret = scheduler.add_task(sleep_task);
+                    assert!(add_ret.is_none());
+                    count = count.wrapping_add(1);
+                    // 进行下一个循环
+                } else {
+                    if should_switch(task.address_space_id) {
+                        // 如果需要跳转到其他地址空间，则不弹出任务，返回需要跳转到的地址空间编号
+                        return TaskResult::ShouldYield(task.address_space_id.into_inner());
+                    } else {
+                        // 直接把任务交给调用者
+                        let task_repr = task.task_repr;
+                        drop(scheduler); // 释放锁
+                        return TaskResult::Task(task_repr);
+                    }
+                }
+            }
+            // 没有任务了，返回已完成
+            None => return TaskResult::Finished,
+        }
+    }
+}
+
+/// 删除一个共享调度器中的任务
+///
+/// * shared_scheduler: 共享调度器的[`NonNull`]指针
+/// * task_repr: 任务的指针
+///
+/// 删除成功返回true，找不到对应的任务返回false
+pub unsafe extern "C" fn shared_delete_task(
+    shared_scheduler: NonNull<()>,
+    task_repr: TaskRepr,
+) -> bool {
+    let mut s: NonNull<SharedScheduler> = shared_scheduler.cast();
+    let mut scheduler = s.as_mut().lock();
+    let len = scheduler.queue_len().unwrap();
+    let mut count = 0;
+    loop {
+        if count >= len {
+            return false;
+        }
+        let next_handle = scheduler.peek_next_task();
+        match next_handle {
+            Some(task) => {
+                if task.task_repr == task_repr {
+                    // 找到了需要删除的任务
+                    let _drop_task = scheduler.next_task().unwrap();
+                    // 之前已经把 count 个任务从头部拿出来放到尾部了，现在要恢复它们
+                    let current_len = scheduler.queue_len().unwrap();
+                    for _ in 0..(current_len - count) {
+                        let next_task = scheduler.next_task().unwrap();
+                        scheduler.add_task(next_task);
+                    }
+                    return true;
+                } else {
+                    // 把任务从头部拿出来再放队列尾部
+                    let next_task = scheduler.next_task().unwrap();
+                    scheduler.add_task(next_task);
+                    count += 1;
+                    // 进入下一次循环
+                }
+            }
+            None => return false,
+        }
+    }
+}
+
+/// 设置任务的状态
+///
+/// * shared_scheduler: 共享调度器的[`NonNull`]指针
+/// * task_repr: 任务的指针
+/// * new_state: 任务的新状态
+///
+/// 通常用来唤醒任务
+pub unsafe extern "C" fn shared_set_task_state(
+    shared_scheduler: NonNull<()>,
+    task_repr: TaskRepr,
+    new_state: TaskState,
+) {
+    let mut s: NonNull<SharedScheduler> = shared_scheduler.cast();
+    let mut scheduler = s.as_mut().lock();
+    let len = scheduler.queue_len().unwrap();
+    let mut count = 0;
+    loop {
+        if count >= len {
+            break;
+        }
+        let next_handle = scheduler.peek_next_task();
+        match next_handle {
+            Some(task) => {
+                if task.task_repr == task_repr {
+                    // 找到了需要设置状态的任务
+                    let change_task = scheduler.peek_next_task_mut().unwrap();
+                    change_task.state = new_state;
+                    // 之前已经把count个任务从头部拿出来放到尾部了，现在要恢复它们
+                    for _ in 0..(len - count) {
+                        let next_task = scheduler.next_task().unwrap();
+                        scheduler.add_task(next_task);
+                    }
+                    break;
+                } else {
+                    // 把任务从头部拿出来再放队列尾部
+                    let next_task = scheduler.next_task().unwrap();
+                    scheduler.add_task(next_task);
+                    count += 1;
+                    // 进入下一次循环
+                }
+            }
+            None => break,
+        }
+    }
+}
-- 
2.34.1

