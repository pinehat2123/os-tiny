From bca45b3e2d8c343993e7d9265966d28c605a6356 Mon Sep 17 00:00:00 2001
From: andre <12485443-Andre_HJR@users.noreply.gitlab.com>
Date: Mon, 6 Mar 2023 06:11:06 -0500
Subject: [PATCH 36/80] async utils upload

---
 async_tiny/async_easy_fs/Cargo.toml          |  14 +
 async_tiny/async_easy_fs/src/lib.rs          |  10 +
 async_tiny/async_mutex/Cargo.toml            |   9 +
 async_tiny/async_mutex/src/lib.rs            | 207 +++++
 async_tiny/async_virtio_driver/Cargo.toml    |  15 +
 async_tiny/async_virtio_driver/src/block.rs  | 831 +++++++++++++++++++
 async_tiny/async_virtio_driver/src/config.rs |   8 +
 async_tiny/async_virtio_driver/src/dma.rs    | 108 +++
 async_tiny/async_virtio_driver/src/lib.rs    |  41 +
 async_tiny/async_virtio_driver/src/log.rs    |  38 +
 async_tiny/async_virtio_driver/src/mmio.rs   | 339 ++++++++
 async_tiny/async_virtio_driver/src/queue.rs  | 451 ++++++++++
 async_tiny/async_virtio_driver/src/sbi.rs    |  69 ++
 async_tiny/async_virtio_driver/src/util.rs   |  25 +
 14 files changed, 2165 insertions(+)
 create mode 100644 async_tiny/async_easy_fs/Cargo.toml
 create mode 100644 async_tiny/async_easy_fs/src/lib.rs
 create mode 100644 async_tiny/async_mutex/Cargo.toml
 create mode 100644 async_tiny/async_mutex/src/lib.rs
 create mode 100644 async_tiny/async_virtio_driver/Cargo.toml
 create mode 100644 async_tiny/async_virtio_driver/src/block.rs
 create mode 100644 async_tiny/async_virtio_driver/src/config.rs
 create mode 100644 async_tiny/async_virtio_driver/src/dma.rs
 create mode 100644 async_tiny/async_virtio_driver/src/lib.rs
 create mode 100644 async_tiny/async_virtio_driver/src/log.rs
 create mode 100644 async_tiny/async_virtio_driver/src/mmio.rs
 create mode 100644 async_tiny/async_virtio_driver/src/queue.rs
 create mode 100644 async_tiny/async_virtio_driver/src/sbi.rs
 create mode 100644 async_tiny/async_virtio_driver/src/util.rs

diff --git a/async_tiny/async_easy_fs/Cargo.toml b/async_tiny/async_easy_fs/Cargo.toml
new file mode 100644
index 0000000..0eda8c7
--- /dev/null
+++ b/async_tiny/async_easy_fs/Cargo.toml
@@ -0,0 +1,14 @@
+[package]
+name = "async_easy_fs"
+version = "0.1.0"
+edition = "2021"
+
+# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
+
+[dependencies]
+async-trait = "0.1.66"
+spin = "0.7"
+lazy_static = { version = "1.4", features = ["spin_no_std"] }
+bit_field = "0.10"
+bitflags = "1.2"
+async-mutex = { path = "../async_mutex", package = "async_mutex" }
\ No newline at end of file
diff --git a/async_tiny/async_easy_fs/src/lib.rs b/async_tiny/async_easy_fs/src/lib.rs
new file mode 100644
index 0000000..f6f5b96
--- /dev/null
+++ b/async_tiny/async_easy_fs/src/lib.rs
@@ -0,0 +1,10 @@
+#![no_std]
+extern crate alloc;
+use alloc::boxed::Box;
+use async_trait::async_trait;
+
+#[async_trait]
+pub trait AsyncBlockDevive {
+    async fn read(&self, block_id: usize, buf: &mut [u8]);
+    async fn write(&self, block_id: usize, buf: &[u8]);
+}
\ No newline at end of file
diff --git a/async_tiny/async_mutex/Cargo.toml b/async_tiny/async_mutex/Cargo.toml
new file mode 100644
index 0000000..ed020dc
--- /dev/null
+++ b/async_tiny/async_mutex/Cargo.toml
@@ -0,0 +1,9 @@
+[package]
+name = "async_mutex"
+version = "0.1.0"
+edition = "2021"
+
+# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
+
+[dependencies]
+event = { path = "../../event", package = "event" }
diff --git a/async_tiny/async_mutex/src/lib.rs b/async_tiny/async_mutex/src/lib.rs
new file mode 100644
index 0000000..d367ad2
--- /dev/null
+++ b/async_tiny/async_mutex/src/lib.rs
@@ -0,0 +1,207 @@
+#![no_std]
+use core::{
+    cell::UnsafeCell,
+    fmt::{Debug, Result, Formatter},
+    ops::{Deref, DerefMut},
+    sync::atomic::{AtomicUsize, Ordering},
+};
+use event::Event;
+
+
+pub struct AsyncMutex<T: ?Sized> {
+    state: AtomicUsize,
+    lock_ops: Event,
+    data: UnsafeCell<T>,
+}
+
+unsafe impl<T: Send + ?Sized> Send for AsyncMutex<T> {}
+unsafe impl<T: Sync + ?Sized> Sync for AsyncMutex<T> {}
+
+impl<T> AsyncMutex<T> {
+    pub const fn new(data: T) -> AsyncMutex<T> {
+        AsyncMutex {
+            state: AtomicUsize::new(0),
+            lock_ops: Event::new(),
+            data: UnsafeCell::new(data),
+        }
+    }
+    
+    pub fn into_inner(self) -> T {
+        self.data.into_inner()
+    }
+}
+
+
+impl<T: ?Sized> AsyncMutex<T> {
+    #[inline]
+    pub async fn lock(&self) -> AsyncMutexGuard<'_, T> {
+        if let Some(guard) = self.try_lock() {
+            return guard;
+        }
+        self.acquire_slow().await;
+        AsyncMutexGuard(self)
+    }
+    #[cold]
+    async fn acquire_slow(&self) {
+        loop {
+            let listener = self.lock_ops.listen();
+
+            match self
+                .state
+                .compare_exchange(0, 1, Ordering::Acquire, Ordering::Acquire)
+                .unwrap_or_else(|x| x)
+            {
+                0 => return,
+
+                1 => {}
+
+                _ => break,
+            }
+
+            listener.await;
+
+            match self
+                .state
+                .compare_exchange(0, 1, Ordering::Acquire, Ordering::Acquire)
+                .unwrap_or_else(|x| x)
+            {
+                0 => return,
+
+                1 => {}
+
+                _ => {
+                    self.lock_ops.notify(1);
+                    break;
+                }
+            }
+        }
+
+        if self.state.fetch_add(2, Ordering::Release) > usize::MAX / 2 {
+            panic!("In case of potential overflow, abort.");
+        }
+
+        let _call = CallOnDrop(|| {
+            self.state.fetch_sub(2, Ordering::Release);
+        });
+
+        loop {
+            let listener = self.lock_ops.listen();
+
+            match self
+                .state
+                .compare_exchange(2, 2 | 1, Ordering::Acquire, Ordering::Acquire)
+                .unwrap_or_else(|x| x)
+            {
+                2 => return,
+
+                s if s % 2 == 1 => {}
+
+                _ => {
+                    self.lock_ops.notify(1);
+                }
+            }
+
+            listener.await;
+
+            if self.state.fetch_or(1, Ordering::Acquire) % 2 == 0 {
+                return;
+            }
+        }
+    }
+
+    #[inline]
+    pub fn try_lock(&self) -> Option<AsyncMutexGuard<'_, T>> {
+        if self
+            .state
+            .compare_exchange(0, 1, Ordering::Acquire, Ordering::Acquire)
+            .is_ok()
+        {
+            Some(AsyncMutexGuard(self))
+        } else {
+            None
+        }
+    }
+    pub fn get_mut(&mut self) -> &mut T {
+        unsafe { &mut *self.data.get() }
+    }
+}
+
+impl <T: Debug + ?Sized> Debug for AsyncMutex<T> {
+    fn fmt(&self, f: &mut Formatter<'_>) -> Result {
+        struct Locked;
+        impl Debug for Locked {
+            fn fmt(&self, f: &mut Formatter<'_>) -> Result {
+                f.write_str("<Locked>")
+            }
+        }
+
+        match self.try_lock() {
+            None => f.debug_struct("AsyncMutex").field("data", &Locked).finish(),
+            Some(guard) => f.debug_struct("AsyncMutex").field("data", &&*guard).finish(),
+        }
+    }
+}
+
+impl<T> From<T> for AsyncMutex<T> {
+    fn from(value: T) -> AsyncMutex<T> {
+        AsyncMutex::new(value)
+    }
+}
+
+impl<T: Default + ?Sized> Default for AsyncMutex<T> {
+    fn default() -> AsyncMutex<T> {
+        AsyncMutex::new(Default::default())
+    }
+}
+
+pub struct AsyncMutexGuard<'a, T: ?Sized>(&'a AsyncMutex<T>);
+
+unsafe impl<T: Send + ?Sized> Send  for AsyncMutexGuard<'_, T> {}
+unsafe impl<T: Sync + ?Sized> Sync  for AsyncMutexGuard<'_, T> {}
+
+impl<'a, T: ?Sized> AsyncMutexGuard<'a, T> {
+    pub fn source(guard: &AsyncMutexGuard<'a, T>) -> &'a AsyncMutex<T> {
+        guard.0
+    }
+}
+
+impl<T: ?Sized> Drop for AsyncMutexGuard<'_, T> {
+    fn drop(&mut self) {
+        self.0.state.fetch_sub(1, Ordering::Release);
+        self.0.lock_ops.notify(1);
+    }
+}
+
+impl<T: core::fmt::Debug + ?Sized> core::fmt::Debug for AsyncMutexGuard<'_, T> {
+    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
+        core::fmt::Debug::fmt(&**self, f)
+    }
+}
+
+impl<T: core::fmt::Display + ?Sized> core::fmt::Display for AsyncMutexGuard<'_, T> {
+    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
+        (**self).fmt(f)
+    }
+}
+
+impl<T: ?Sized> Deref for AsyncMutexGuard<'_, T> {
+    type Target = T;
+
+    fn deref(&self) -> &T {
+        unsafe { &*self.0.data.get() }
+    }
+}
+
+impl<T: ?Sized> DerefMut for AsyncMutexGuard<'_, T> {
+    fn deref_mut(&mut self) -> &mut T {
+        unsafe { &mut *self.0.data.get() }
+    }
+}
+
+struct CallOnDrop<F: Fn()>(F);
+
+impl<F: Fn()> Drop for CallOnDrop<F> {
+    fn drop(&mut self) {
+        (self.0)();
+    }
+}
\ No newline at end of file
diff --git a/async_tiny/async_virtio_driver/Cargo.toml b/async_tiny/async_virtio_driver/Cargo.toml
new file mode 100644
index 0000000..a9cc6f3
--- /dev/null
+++ b/async_tiny/async_virtio_driver/Cargo.toml
@@ -0,0 +1,15 @@
+[package]
+name = "async_virtio_driver"
+version = "0.1.0"
+edition = "2021"
+
+# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
+
+[dependencies]
+spin = "0.7"
+nb = "1.0.0"
+volatile = "0.2"
+bitflags = "1.2"
+lazy_static = { version = "1.4", features = ["spin_no_std"] }
+event = { path = "../../event", package="event" }
+safe_cell = { path = "../../safe_cell", package="safe_cell" }
diff --git a/async_tiny/async_virtio_driver/src/block.rs b/async_tiny/async_virtio_driver/src/block.rs
new file mode 100644
index 0000000..16a4f79
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/block.rs
@@ -0,0 +1,831 @@
+//! 虚拟块设备前端驱动
+//! ref: https://github.com/rcore-os/virtio-drivers/blob/master/src/blk.rs
+//! thanks!
+//!
+//! BlockFuture 的 Send 和 Sync：
+//! + inner 成员是 Send 和 Sync 的，_req_type 和 response 成员暂时不会用到，因此从成员变量看来是 Send 和 Sync 的
+//! + poll 方法借助了 Mutex 实现内部可变性，在并发场景下多个 poll 操作一起运行的时候，有锁机制保证操作的原子性，因此是 Sync 的
+//! 因此个人觉得 BLockFuture 是 Send 和 Sync 的
+//!
+//! VirtioBlock 设计需求分析：
+//! + 需要在并发场景下执行 async_read 或 async_write 或 ack_interrupt 操作，
+//! 因此这三个方法都必须是 &self 而不能是 &mut self，因此通过 Mutex 提供内部可变性，并保证并发安全
+//! + 需要想清楚哪些操作必须是原子的，必须按顺序来，否则会出问题
+//! + 比如多个协程都需要执行 async_read，这时候需要往虚拟队列中添加描述符，然后通知设备，
+//! 如果添加描述符和通知设备两个操作不是原子的话，可能会出问题。（这里可能两个操作不应该是原子的，只是举个例子，说明系统里面可能会有这样的情况）
+//!
+//! todo: 弄清楚哪些操作需要同步，哪些部分需要加锁
+use super::{config::*, mmio::VirtIOHeader, queue::VirtQueue, util::AsBuf, *};
+use alloc::sync::Arc;
+use bitflags::bitflags;
+use core::{
+    cell::RefCell,
+    future::Future,
+    pin::Pin,
+    ptr::NonNull,
+    task::{Context, Poll},
+};
+use event::Event;
+use spin::Mutex;
+use volatile::Volatile;
+
+/// 块设备读写返回的`Future`
+///
+/// 目前飓风内核没有用到这个结构，但先留着
+pub struct BlockFuture {
+    /// 该块设备的内部结构，用于 poll 操作的时候判断请求是否完成
+    /// 如果完成了也会对这里的值做相关处理
+    inner: Arc<Mutex<VirtIOBlockInner>>,
+    /// IO 请求的描述符链头部
+    head: u16,
+    /// IO 请求缓冲区
+    #[allow(unused)]
+    req: NonNull<BlockReq>,
+    /// IO 回应缓冲区
+    resp: NonNull<BlockResp>,
+    /// 是否是第一次 poll
+    first_poll: RefCell<bool>,
+}
+
+impl Future for BlockFuture {
+    type Output = Result<()>;
+    // warn: 这里需要仔细考虑操作的原子性
+    // 这里可能有外部中断进入
+    fn poll(self: Pin<&mut Self>, _cx: &mut Context<'_>) -> Poll<Self::Output> {
+        let mut inner = self.inner.lock();
+        let (h, q) = inner.header_and_queue_mut();
+        unsafe {
+            // 如果是第一次 Poll，则通知设备，直接返回 Pending
+            if *(self.first_poll.as_ptr()) {
+                h.notify(0);
+                *(self.first_poll.borrow_mut()) = false;
+                return Poll::Pending;
+            }
+        }
+        match q.can_pop() {
+            true => {
+                let pop_ret = q.pop_used()?;
+                assert_eq!(self.head, pop_ret.0);
+                unsafe {
+                    let resp = *self.resp.as_ptr();
+                    match resp.status {
+                        BlockRespStatus::Ok => {
+                            if h.ack_interrupt() {
+                                return Poll::Ready(Ok(()));
+                            } else {
+                                return Poll::Ready(Err(VirtIOError::AckInterruptError));
+                            }
+                        }
+                        _ => return Poll::Ready(Err(VirtIOError::DeciveResponseError)),
+                    }
+                }
+            }
+            false => {
+                // 这里不进行唤醒，直接返回 pending
+                // 外部中断到来的时候在内核里面唤醒
+                Poll::Pending
+            }
+        }
+    }
+}
+
+unsafe impl Send for BlockFuture {}
+unsafe impl Sync for BlockFuture {}
+
+/// 虚拟块设备
+/// 常量泛型参数：一个块中的扇区数
+///
+/// 扇区 vs 块：
+/// * 扇区是存储介质的最小存储单位，是物理上的概念
+/// * 块是文件系统的最小存储单位，是逻辑上的概念
+pub struct VirtIOBlock<const N: usize> {
+    /// 块设备的内部内容
+    lock_inner: Arc<Mutex<VirtIOBlockInner>>,
+    /// 不上锁的 inner，只读，用于中断处理的时候读取相应的状态
+    ///
+    /// todo: 不要通过 NonNull 所有权和生命周期机制，采用更加 Rust 的写法
+    unlock_queue: NonNull<VirtQueue>,
+    /// 容量
+    #[allow(unused)]
+    capacity: usize,
+    /// 扇区大小
+    pub sector_size: u32,
+    /// 添加一个[`Event`]成员后，完美实现块设备驱动
+    pub wake_ops: Event,
+}
+
+// todo: 尽量让 VirtIOBlock 天然 Send 和 Sync
+unsafe impl<const N: usize> Send for VirtIOBlock<N> {}
+unsafe impl<const N: usize> Sync for VirtIOBlock<N> {}
+
+/// 并发场景中经常需要 VirtIOHeader 和 VirtQueue 共同完成一些原子操作
+/// 因此把这两者放到一个结构体里面
+pub struct VirtIOBlockInner {
+    /// MMIO 头部
+    pub header: &'static mut VirtIOHeader,
+    /// 虚拟队列
+    pub queue: VirtQueue,
+    /// IO 请求池
+    pub req_pool: [BlockReq; VIRT_QUEUE_SIZE],
+    /// IO 回应池
+    pub resp_pool: [BlockResp; VIRT_QUEUE_SIZE],
+}
+
+impl VirtIOBlockInner {
+    pub fn header_and_queue(&self) -> (&VirtIOHeader, &VirtQueue) {
+        (self.header, &self.queue)
+    }
+
+    pub fn header_and_queue_mut(&mut self) -> (&mut VirtIOHeader, &mut VirtQueue) {
+        (&mut self.header, &mut self.queue)
+    }
+
+    pub fn header_queue_req_resp(&self) -> (&VirtIOHeader, &VirtQueue, &[BlockReq], &[BlockResp]) {
+        (self.header, &self.queue, &self.req_pool, &self.resp_pool)
+    }
+
+    pub fn header_queue_req_resp_mut(
+        &mut self,
+    ) -> (
+        &mut VirtIOHeader,
+        &mut VirtQueue,
+        &mut [BlockReq],
+        &mut [BlockResp],
+    ) {
+        (
+            self.header,
+            &mut self.queue,
+            &mut self.req_pool,
+            &mut self.resp_pool,
+        )
+    }
+}
+
+impl<const N: usize> VirtIOBlock<N> {
+    /// 以异步方式创建虚拟块设备驱动
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// async {
+    ///     let virtio_block = VirtIOBlock::async_new().await.unwrap();   
+    /// }
+    /// ```
+    pub async fn async_new(header: &'static mut VirtIOHeader) -> Result<VirtIOBlock<N>> {
+        if !header.verify() {
+            return Err(VirtIOError::HeaderVerifyError);
+        }
+        header.begin_init(|f| {
+            let features = BlockFeature::from_bits_truncate(f);
+            println!("[virtio] block device features: {:?}", features);
+            // 对这些 features 进行谈判
+            let supported_featuers = BlockFeature::empty();
+            (features & supported_featuers).bits()
+        });
+
+        // 读取配置空间
+        let config = unsafe { &mut *(header.config_space() as *mut BlockConfig) };
+        println!("[virtio] config: {:?}", config);
+        println!(
+            "[virtio] found a block device of size {} KB",
+            config.capacity.read() / 2
+        );
+
+        let queue = VirtQueue::async_new(header, 0, VIRT_QUEUE_SIZE as u16).await?;
+
+        header.finish_init();
+
+        let req_pool = [BlockReq {
+            type_: BlockReqType::Discard,
+            reserved: 0,
+            sector: 0,
+        }; VIRT_QUEUE_SIZE];
+        let resp_pool = [BlockResp::default(); VIRT_QUEUE_SIZE];
+
+        let inner = VirtIOBlockInner {
+            header,
+            queue,
+            req_pool,
+            resp_pool,
+        };
+        let lock_inner = Arc::new(Mutex::new(inner));
+        let queue_ptr = lock_inner.lock().header_and_queue().1 as *const _ as *mut VirtQueue;
+
+        Ok(VirtIOBlock {
+            lock_inner,
+            unlock_queue: NonNull::new(queue_ptr).unwrap(),
+            capacity: config.capacity.read() as usize,
+            sector_size: config.sector_size.read(),
+            wake_ops: Event::new(),
+        })
+    }
+    /// 同步方式创建异步块设备驱动
+    ///
+    /// 飓风内核目前使用这种方式
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// let virtio_block = VirtIOBlock::new().await.unwrap();
+    /// ```
+    pub fn new(header: &'static mut VirtIOHeader) -> Result<Self> {
+        if !header.verify() {
+            return Err(VirtIOError::HeaderVerifyError);
+        }
+        header.begin_init(|f| {
+            let features = BlockFeature::from_bits_truncate(f);
+            println!("[virtio] block device features: {:?}", features);
+            // 对这些 features 进行谈判
+            let supported_featuers = BlockFeature::empty();
+            (features & supported_featuers).bits()
+        });
+
+        // 读取配置空间
+        let config = unsafe { &mut *(header.config_space() as *mut BlockConfig) };
+        // println!("[virtio] config: {:?}", config);
+        println!(
+            "[virtio] found a block device of size {} KB",
+            config.capacity.read() / 2
+        );
+
+        let queue = VirtQueue::new(header, 0, VIRT_QUEUE_SIZE as u16)?;
+
+        header.finish_init();
+
+        let req_pool = [BlockReq {
+            type_: BlockReqType::Discard,
+            reserved: 0,
+            sector: 0,
+        }; VIRT_QUEUE_SIZE];
+        let resp_pool = [BlockResp::default(); VIRT_QUEUE_SIZE];
+
+        let inner = VirtIOBlockInner {
+            header,
+            queue,
+            req_pool,
+            resp_pool,
+        };
+        let lock_inner = Arc::new(Mutex::new(inner));
+        let queue_ptr = lock_inner.lock().header_and_queue().1 as *const _ as *mut VirtQueue;
+        Ok(VirtIOBlock {
+            lock_inner,
+            unlock_queue: NonNull::new(queue_ptr).unwrap(),
+            capacity: config.capacity.read() as usize,
+            sector_size: config.sector_size.read(),
+            wake_ops: Event::new(),
+        })
+    }
+    /// 通知设备 virtio 外部中断已经处理完成
+    ///
+    /// 目前飓风内核没有用到这个函数
+    pub fn ack_interrupt(&self) -> bool {
+        self.lock_inner.lock().header.ack_interrupt()
+    }
+    /// 以异步方式读取一个扇区
+    ///
+    /// 目前飓风内核没有用到这个接口(旧的设计)
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// todo!()
+    /// ```
+    pub fn async_read_sector(&self, sector_id: usize, buf: &mut [u8]) -> BlockFuture {
+        // 缓冲区大小必须等于扇区大小
+        if buf.len() != self.sector_size as usize {
+            panic!(
+                "[virtio] buffer size must equal to sector size - {}!",
+                self.sector_size
+            );
+        }
+        let mut inner = self.lock_inner.lock();
+        let (_h, q, reqs, resps) = inner.header_queue_req_resp_mut();
+
+        // 空闲描述符表的头部
+        let free_head = q.free_head();
+
+        // IO 请求
+        let req = &mut reqs[free_head as usize];
+        req.type_ = BlockReqType::In;
+        req.reserved = 0;
+        req.sector = sector_id as u64;
+
+        // IO 回应
+        let resp = &mut resps[free_head as usize];
+
+        let head = q
+            .add_buf(&[req.as_buf()], &[buf, resp.as_buf_mut()])
+            .expect("[virtio] virtual queue add buf error");
+
+        let req_ptr = req.as_buf() as *const _ as *mut BlockReq;
+        let resp_ptr = resp.as_buf() as *const _ as *mut BlockResp;
+
+        // 不在这里通知设备，在 BlockFuture 第一次 poll 的时候通知
+        // h.notify(0);
+        BlockFuture {
+            inner: Arc::clone(&self.lock_inner),
+            head,
+            req: NonNull::new(req_ptr).unwrap(),
+            resp: NonNull::new(resp_ptr).unwrap(),
+            first_poll: RefCell::new(true),
+        }
+    }
+    /// 以异步方式写入一个扇区
+    ///
+    /// 目前飓风内核没有用到这个接口(旧的设计)
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// todo!()
+    /// ```
+    pub fn async_write_sector(&self, sector_id: usize, buf: &[u8]) -> BlockFuture {
+        if buf.len() != self.sector_size as usize {
+            panic!(
+                "[virtio] buffer size must equal to sector size - {}!",
+                self.sector_size
+            );
+        }
+
+        let mut inner = self.lock_inner.lock();
+        let (_h, q, reqs, resps) = inner.header_queue_req_resp_mut();
+
+        // 空闲描述符表头部
+        let free_head = q.free_head();
+
+        // IO 请求
+        let req = &mut reqs[free_head as usize];
+        req.type_ = BlockReqType::Out;
+        req.reserved = 0;
+        req.sector = sector_id as u64;
+
+        // IO 回应
+        let resp = &mut resps[free_head as usize];
+
+        let head = q
+            .add_buf(&[req.as_buf(), buf], &[resp.as_buf_mut()])
+            .expect("[virtio] virtual queue add buf error");
+
+        let req_ptr = req.as_buf() as *const _ as *mut BlockReq;
+        let resp_ptr = resp.as_buf() as *const _ as *mut BlockResp;
+
+        // 不在这里通知设备，在 BlockFuture 第一次 poll 的时候通知
+        // h.notify(0);
+        BlockFuture {
+            inner: Arc::clone(&self.lock_inner),
+            head,
+            req: NonNull::new(req_ptr).unwrap(),
+            resp: NonNull::new(resp_ptr).unwrap(),
+            first_poll: RefCell::new(true),
+        }
+    }
+    /// 异步方式读取一个块
+    ///
+    /// unused
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// todo!()
+    /// ```
+    pub async fn async_read_block(&self, block_id: usize, buf: &mut [u8]) -> Result<()> {
+        // 块大小 = 一个块中的扇区数 * 扇区大小
+        let block_size = self.sector_size as usize * N;
+        if buf.len() != block_size {
+            panic!(
+                "[virtio] buffer size must equal to block size - {}!",
+                block_size
+            );
+        }
+        for (idx, b) in buf.chunks_mut(self.sector_size as usize).enumerate() {
+            self.async_read_sector(block_id + idx, b).await?;
+        }
+        Ok(())
+    }
+    /// 异步方式写入一个块
+    ///
+    /// unused
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// todo!()
+    /// ```
+    pub async fn async_write_block(&self, block_id: usize, buf: &[u8]) -> Result<()> {
+        // 块大小 = 一个块中的扇区数 * 扇区大小
+        let block_size = self.sector_size as usize * N;
+        if buf.len() != block_size {
+            panic!(
+                "[virtio] buffer size must equal to block size - {}!",
+                block_size
+            );
+        }
+        for (idx, b) in buf.chunks(self.sector_size as usize).enumerate() {
+            self.async_write_sector(block_id + idx, b).await?;
+        }
+        Ok(())
+    }
+    /// 异步方式读取一个扇区
+    ///
+    /// 飓风内核通过这个接口实现块设备的异步读取
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// async {
+    ///     # let virtio_block = VirtIOBlock::new();
+    ///     # const SECTOR_SIZE: usize = 512;
+    ///
+    ///     let mut buf = [0u8; SECTOR_SIZE];
+    ///     virtio_block.read_sector_event(0, &mut buf).await.unwrap();       
+    /// }
+    /// ```
+    pub async fn read_sector_event(&self, sector_id: usize, buf: &mut [u8]) -> Result<()> {
+        // 开始监听
+        let listener = self.wake_ops.listen();
+        // 缓冲区大小必须等于扇区大小
+        if buf.len() != self.sector_size as usize {
+            panic!(
+                "[virtio] buffer size must equal to sector size - {}!",
+                self.sector_size
+            );
+        }
+        let req = BlockReq {
+            type_: BlockReqType::In,
+            reserved: 0,
+            sector: sector_id as u64,
+        };
+        let mut inner = self.lock_inner.lock();
+        let mut resp = BlockResp::default();
+
+        let (h, q) = inner.header_and_queue_mut();
+
+        q.add_buf(&[req.as_buf()], &[buf, resp.as_buf_mut()])
+            .expect("[virtio] virtual queue add buf error");
+
+        h.notify(0);
+
+        listener.await;
+
+        q.pop_used()?;
+
+        match resp.status {
+            BlockRespStatus::Ok => Ok(()),
+            _ => Err(VirtIOError::IOError),
+        }
+    }
+    /// 异步方式写入一个扇区
+    ///
+    /// 飓风内核通过这个接口实现块设备的异步写入
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// async {
+    ///     # let virtio_block = VirtIOBlock::new();
+    ///     # const SECTOR_SIZE: usize = 512;
+    ///
+    ///     let buf = [1u8; SECTOR_SIZE];
+    ///     virtio_block.write_sector_event(0, &buf).await.unwrap();       
+    /// }
+    /// ```
+    pub async fn write_serctor_event(&self, sector_id: usize, buf: &[u8]) -> Result<()> {
+        // 开始监听
+        let listener = self.wake_ops.listen();
+        // 缓冲区大小必须等于扇区大小
+        if buf.len() != self.sector_size as usize {
+            panic!(
+                "[virtio] buffer size must equal to sector size - {}!",
+                self.sector_size
+            );
+        }
+        let req = BlockReq {
+            type_: BlockReqType::Out,
+            reserved: 0,
+            sector: sector_id as u64,
+        };
+        let mut inner = self.lock_inner.lock();
+        let mut resp = BlockResp::default();
+
+        let (h, q) = inner.header_and_queue_mut();
+
+        q.add_buf(&[req.as_buf(), buf], &[resp.as_buf_mut()])
+            .expect("[virtio] virtual queue add buf error");
+
+        h.notify(0);
+
+        listener.await;
+
+        q.pop_used()?;
+        match resp.status {
+            BlockRespStatus::Ok => Ok(()),
+            _ => Err(VirtIOError::IOError),
+        }
+    }
+    /// 异步方式读取一个块
+    ///
+    /// 飓风内核通过这个接口实现块设备的异步读取
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// async {
+    ///     # let virtio_block = VirtIOBlock::new();
+    ///     # const BLOCK_SIZE: usize = 512;
+    ///
+    ///     let mut buf = [0u8; BLOCK_SIZE];
+    ///     virtio_block.read_block_event(0, &mut buf).await.unwrap();       
+    /// }
+    /// ```
+    pub async fn read_block_event(&self, block_id: usize, buf: &mut [u8]) -> Result<()> {
+        // 块大小 = 一个块中的扇区数 * 扇区大小
+        let block_size = self.sector_size as usize * N;
+        if buf.len() != block_size {
+            panic!(
+                "[virtio] buffer size {} not equal to block size - {}!",
+                buf.len(),
+                block_size
+            );
+        }
+        for (idx, b) in buf.chunks_mut(self.sector_size as usize).enumerate() {
+            self.read_sector_event(block_id + idx, b).await?;
+        }
+        Ok(())
+    }
+    /// 异步方式写入一个块
+    ///
+    /// 飓风内核通过这个接口实现块设备的异步写入
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// async {
+    ///     # let virtio_block = VirtIOBlock::new();
+    ///     # const BLOCK_SIZE: usize = 512;
+    ///
+    ///     let buf = [1u8; BLOCK_SIZE];
+    ///     virtio_block.write_block_event(0, &buf).await.unwrap();       
+    /// }
+    /// ```
+    pub async fn write_block_event(&self, block_id: usize, buf: &[u8]) -> Result<()> {
+        // 块大小 = 一个块中的扇区数 * 扇区大小
+        let block_size = self.sector_size as usize * N;
+        if buf.len() != block_size {
+            panic!(
+                "[virtio] buffer size must equal to block size - {}!",
+                block_size
+            );
+        }
+        for (idx, b) in buf.chunks(self.sector_size as usize).enumerate() {
+            self.write_serctor_event(block_id + idx, b).await?;
+        }
+        Ok(())
+    }
+    /// 同步方式读取一个扇区
+    ///
+    /// unused
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// todo!()
+    /// ```
+    pub fn read_sector(&self, block_id: usize, buf: &mut [u8]) -> Result<()> {
+        // 缓冲区大小必须等于扇区大小
+        if buf.len() != self.sector_size as usize {
+            panic!(
+                "[virtio] buffer size must equal to sector size - {}!",
+                self.sector_size
+            );
+        }
+        let req = BlockReq {
+            type_: BlockReqType::In,
+            reserved: 0,
+            sector: block_id as u64,
+        };
+        let mut inner = self.lock_inner.lock();
+        let mut resp = BlockResp::default();
+
+        let (h, q) = inner.header_and_queue_mut();
+
+        q.add_buf(&[req.as_buf()], &[buf, resp.as_buf_mut()])
+            .expect("[virtio] virtual queue add buf error");
+
+        h.notify(0);
+
+        while !q.can_pop() {}
+        q.pop_used()?;
+        match resp.status {
+            BlockRespStatus::Ok => Ok(()),
+            _ => Err(VirtIOError::IOError),
+        }
+    }
+    /// 同步方式写入一个扇区
+    ///
+    /// unused
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// todo!()
+    /// ```
+    pub fn write_sector(&self, block_id: usize, buf: &[u8]) -> Result<()> {
+        // 缓冲区大小必须等于扇区大小
+        if buf.len() != self.sector_size as usize {
+            panic!(
+                "[virtio] buffer size must equal to sector size - {}!",
+                self.sector_size
+            );
+        }
+        let req = BlockReq {
+            type_: BlockReqType::Out,
+            reserved: 0,
+            sector: block_id as u64,
+        };
+        let mut inner = self.lock_inner.lock();
+        let mut resp = BlockResp::default();
+
+        let (h, q) = inner.header_and_queue_mut();
+
+        q.add_buf(&[req.as_buf(), buf], &[resp.as_buf_mut()])
+            .expect("[virtio] virtual queue add buf error");
+
+        h.notify(0);
+
+        while !q.can_pop() {}
+        q.pop_used()?;
+        match resp.status {
+            BlockRespStatus::Ok => Ok(()),
+            _ => Err(VirtIOError::IOError),
+        }
+    }
+    /// 处理 virtio 外部中断
+    ///
+    /// 在飓风内核的外部中断处理函数里面被调用
+    ///
+    /// todo: 仔细考虑这里的操作原子性
+    ///
+    /// # Example:
+    ///
+    /// ```
+    /// # static VIRTIO_BLOCK: VirtIOBlock;
+    /// extern "C" fn external_interrupt() {
+    ///     let intr_ret = VIRTIO_BLOCK.handle_interrupt().unwrap();  
+    /// }
+    /// ```
+    pub unsafe fn handle_interrupt(&self) -> Result<InterruptRet> {
+        // 这里使用获取不加锁的 inner
+        let q = self.unlock_queue.as_ref();
+        if !q.can_pop() {
+            return Err(VirtIOError::IOError);
+        }
+        let (idx, _len) = q.next_used()?;
+        let desc = q.descriptor(idx as usize);
+        let req_va = virtio_phys_to_virt(desc.paddr.read() as usize);
+        let req = &*(req_va as *const BlockReq);
+        let ret = match req.type_ {
+            BlockReqType::In => InterruptRet::Read(req.sector),
+            BlockReqType::Out => InterruptRet::Write(req.sector),
+            _ => InterruptRet::Other,
+        };
+        Ok(ret)
+    }
+}
+
+bitflags! {
+    struct BlockFeature: u64 {
+        /// Device supports request barriers. (legacy)
+        const BARRIER       = 1 << 0;
+        /// Maximum size of any single segment is in `size_max`.
+        const SIZE_MAX      = 1 << 1;
+        /// Maximum number of segments in a request is in `seg_max`.
+        const SEG_MAX       = 1 << 2;
+        /// Disk-style geometry specified in geometry.
+        const GEOMETRY      = 1 << 4;
+        /// Device is read-only.
+        const RO            = 1 << 5;
+        /// Block size of disk is in `blk_size`.
+        const BLK_SIZE      = 1 << 6;
+        /// Device supports scsi packet commands. (legacy)
+        const SCSI          = 1 << 7;
+        /// Cache flush command support.
+        const FLUSH         = 1 << 9;
+        /// Device exports information on optimal I/O alignment.
+        const TOPOLOGY      = 1 << 10;
+        /// Device can toggle its cache between writeback and writethrough modes.
+        const CONFIG_WCE    = 1 << 11;
+        /// Device can support discard command, maximum discard sectors size in
+        /// `max_discard_sectors` and maximum discard segment number in
+        /// `max_discard_seg`.
+        const DISCARD       = 1 << 13;
+        /// Device can support write zeroes command, maximum write zeroes sectors
+        /// size in `max_write_zeroes_sectors` and maximum write zeroes segment
+        /// number in `max_write_zeroes_seg`.
+        const WRITE_ZEROES  = 1 << 14;
+
+        // device independent
+        const NOTIFY_ON_EMPTY       = 1 << 24; // legacy
+        const ANY_LAYOUT            = 1 << 27; // legacy
+        const RING_INDIRECT_DESC    = 1 << 28;
+        const RING_EVENT_IDX        = 1 << 29;
+        const UNUSED                = 1 << 30; // legacy
+        const VERSION_1             = 1 << 32; // detect legacy
+
+        // the following since virtio v1.1
+        const ACCESS_PLATFORM       = 1 << 33;
+        const RING_PACKED           = 1 << 34;
+        const IN_ORDER              = 1 << 35;
+        const ORDER_PLATFORM        = 1 << 36;
+        const SR_IOV                = 1 << 37;
+        const NOTIFICATION_DATA     = 1 << 38;
+    }
+}
+
+/// 块设备配置
+#[repr(C)]
+#[derive(Debug)]
+struct BlockConfig {
+    /// 扇区数目
+    capacity: Volatile<u64>,
+    size_max: Volatile<u32>,
+    seg_max: Volatile<u32>,
+    cylinders: Volatile<u16>,
+    heads: Volatile<u8>,
+    sectors: Volatile<u8>,
+    /// 扇区大小
+    sector_size: Volatile<u32>,
+    physical_block_exp: Volatile<u8>,
+    alignment_offset: Volatile<u8>,
+    min_io_size: Volatile<u16>,
+    opt_io_size: Volatile<u32>,
+    // ... ignored
+}
+
+/// 块设备请求
+#[repr(C)]
+#[derive(Debug, Clone, Copy)]
+pub struct BlockReq {
+    type_: BlockReqType,
+    reserved: u32,
+    sector: u64,
+}
+
+/// 块设备回应
+#[repr(C)]
+#[derive(Debug, Clone, Copy)]
+pub struct BlockResp {
+    status: BlockRespStatus,
+}
+
+/// 块设备请求类型
+#[repr(u32)]
+#[derive(Debug, Clone, Copy)]
+enum BlockReqType {
+    In = 0,
+    Out = 1,
+    #[allow(unused)]
+    Flush = 4,
+    Discard = 11,
+    #[allow(unused)]
+    WriteZeroes = 13,
+}
+
+/// 块设备回应状态
+#[repr(u8)]
+#[derive(Debug, Eq, PartialEq, Clone, Copy)]
+enum BlockRespStatus {
+    #[allow(unused)]
+    Ok = 0,
+    #[allow(unused)]
+    IoErr = 1,
+    #[allow(unused)]
+    Unsupported = 2,
+    NotReady = 3,
+}
+
+impl Default for BlockResp {
+    fn default() -> Self {
+        BlockResp {
+            status: BlockRespStatus::NotReady,
+        }
+    }
+}
+
+unsafe impl AsBuf for BlockReq {}
+unsafe impl AsBuf for BlockResp {}
+
+#[derive(Debug)]
+/// 中断响应返回值
+pub enum InterruptRet {
+    /// 读请求完成的块
+    Read(u64),
+    /// 写请求完成的块
+    Write(u64),
+    /// 其他
+    Other,
+}
+
+extern "C" {
+    /// 内核提供的物理地址到虚拟地址的转换函数
+    fn virtio_phys_to_virt(paddr: usize) -> usize;
+}
diff --git a/async_tiny/async_virtio_driver/src/config.rs b/async_tiny/async_virtio_driver/src/config.rs
new file mode 100644
index 0000000..abdce25
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/config.rs
@@ -0,0 +1,8 @@
+/// 页大小
+pub const PAGE_SIZE: usize = 0x1000;
+
+/// DMA 分配的最大轮询次数
+pub const MAX_DMA_ALLOC_COUNT: u32 = 0x10;
+
+/// 虚拟队列大小
+pub const VIRT_QUEUE_SIZE: usize = 16;
diff --git a/async_tiny/async_virtio_driver/src/dma.rs b/async_tiny/async_virtio_driver/src/dma.rs
new file mode 100644
index 0000000..6f4b45e
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/dma.rs
@@ -0,0 +1,108 @@
+use super::config::*;
+use super::*;
+/// "DMA" 实现
+/// ref: https://github.com/rcore-os/virtio-drivers/blob/master/src/hal.rs
+/// thanks!
+use core::future::Future;
+use core::pin::Pin;
+use core::task::{Context, Poll};
+
+type VirtualAddress = usize;
+type PhysicalAddress = usize;
+
+#[derive(Debug)]
+pub struct DMA {
+    paddr: usize,
+    pages: usize,
+}
+
+// async-virtio-driver/src/dma.rs-COMMENT: 2022-11-05 Sat Andre :] fix the comment, change the doc_comment to line comment
+// 这些函数在操作系统内核里面定义
+extern "C" {
+    // 申请分配一定页数的连续的内存，返回起始物理地址
+    fn virtio_dma_alloc(pages: usize) -> PhysicalAddress;
+    // 回收一定页数的内存
+    fn virtio_dma_dealloc(paddr: PhysicalAddress, pages: usize) -> i32;
+    // 内核提供的物理地址到虚拟地址的转换函数
+    fn virtio_phys_to_virt(paddr: PhysicalAddress) -> VirtualAddress;
+}
+
+pub struct DMAAllocFuture {
+    pages: u32,
+    count: u32,
+}
+
+impl Future for DMAAllocFuture {
+    type Output = DMA;
+    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
+        if self.count > MAX_DMA_ALLOC_COUNT {
+            panic!("[virtio] no memory space avaiable for dma");
+        }
+        let paddr = unsafe { virtio_dma_alloc(self.pages as usize) };
+        match paddr {
+            0 => {
+                self.count += 1;
+                cx.waker().wake_by_ref();
+                Poll::Pending
+            }
+            pa => Poll::Ready(DMA {
+                paddr: pa,
+                pages: self.pages as usize,
+            }),
+        }
+    }
+}
+
+unsafe impl Send for DMAAllocFuture {}
+unsafe impl Sync for DMAAllocFuture {}
+
+impl DMA {
+    // 先用这种方式创建 DMA，后面考虑使用 alloc 方法
+    pub fn new(pages: usize) -> Result<Self> {
+        let paddr = unsafe { virtio_dma_alloc(pages) };
+        if paddr == 0 {
+            return Err(VirtIOError::DMAAllocError);
+        }
+        Ok(DMA { paddr, pages })
+    }
+
+    /// 向操作系统内核申请分配 DMA 空间
+    pub fn alloc(pages: usize) -> DMAAllocFuture {
+        DMAAllocFuture {
+            pages: pages as u32,
+            count: 0,
+        }
+    }
+
+    /// 起始物理地址
+    pub fn start_physical_address(&self) -> usize {
+        self.paddr as usize
+    }
+
+    /// 起始虚拟地址
+    pub fn start_virtual_address(&self) -> usize {
+        unsafe { virtio_phys_to_virt(self.paddr as usize) }
+    }
+
+    /// 物理页号
+    pub fn ppn(&self) -> usize {
+        self.paddr >> 12
+    }
+
+    /// 转换成 buffer
+    #[allow(unused)]
+    pub unsafe fn as_buf(&self) -> &'static mut [u8] {
+        core::slice::from_raw_parts_mut(
+            self.start_virtual_address() as _,
+            PAGE_SIZE * self.pages as usize,
+        )
+    }
+}
+
+/// DMA 在生命周期结束的时候需要在内核里面回收相应的内存空间
+impl Drop for DMA {
+    fn drop(&mut self) {
+        let err = unsafe { virtio_dma_dealloc(self.paddr, self.pages) };
+        assert_eq!(err, 0, "[virtio] failed to deallocate DMA");
+    }
+}
diff --git a/async_tiny/async_virtio_driver/src/lib.rs b/async_tiny/async_virtio_driver/src/lib.rs
new file mode 100644
index 0000000..a53e214
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/lib.rs
@@ -0,0 +1,41 @@
+#![no_std]
+
+mod config;
+mod dma;
+mod log;
+pub mod mmio;
+pub mod queue;
+mod sbi;
+mod util;
+
+extern crate alloc;
+
+pub type Result<T = ()> = core::result::Result<T, VirtIOError>;
+
+// pub use mmio::*;
+// pub use queue::*;
+// pub use block::*;
+/// 虚拟设备错误
+#[derive(Debug)]
+pub enum VirtIOError {
+    /// 申请 DMA 空间分配错误
+    DMAAllocError,
+    /// 虚拟队列已经被占用
+    QueueInUsed(usize),
+    /// 非法参数
+    InvalidParameter,
+    /// 溢出
+    Overflow,
+    /// 已用环没准备好
+    UsedRingNotReady,
+    /// Header 检查错误
+    HeaderVerifyError,
+    /// 数据传输错误
+    /// 出现在虚拟设备返回一个状态不是 Ok 的回应
+    /// 和数据没准备好却进入了外部中断处理方法
+    IOError,
+    /// 回应设备外部中断错误
+    AckInterruptError,
+    /// 设备回应错误
+    DeciveResponseError,
+}
diff --git a/async_tiny/async_virtio_driver/src/log.rs b/async_tiny/async_virtio_driver/src/log.rs
new file mode 100644
index 0000000..f56d2ea
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/log.rs
@@ -0,0 +1,38 @@
+use crate::sbi::*;
+use core::fmt::{self, Write};
+use rv_lock::Lock;
+struct Stdout;
+
+// 暂时不用关中断的锁lock::Lock，考虑多个硬件线程的情况
+static STDOUT_LOCK: Lock<()> = Lock::new(());
+
+impl Write for Stdout {
+    fn write_str(&mut self, s: &str) -> fmt::Result {
+        let mut buffer = [0u8; 4];
+        STDOUT_LOCK.lock();
+        for c in s.chars() {
+            for code_point in c.encode_utf8(&mut buffer).as_bytes().iter() {
+                console_putchar(*code_point as usize);
+            }
+        }
+        Ok(())
+    }
+}
+
+pub fn print(args: fmt::Arguments) {
+    Stdout.write_fmt(args).unwrap();
+}
+
+#[macro_export]
+macro_rules! print {
+    ($fmt: literal $(, $($arg: tt)+)?) => {
+        $crate::log::print(format_args!($fmt $(, $($arg)+)?));
+    }
+}
+
+#[macro_export]
+macro_rules! println {
+    ($fmt: literal $(, $($arg: tt)+)?) => {
+        $crate::log::print(format_args!(concat!($fmt, "\n") $(, $($arg)+)?));
+    }
+}
diff --git a/async_tiny/async_virtio_driver/src/mmio.rs b/async_tiny/async_virtio_driver/src/mmio.rs
new file mode 100644
index 0000000..00255bf
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/mmio.rs
@@ -0,0 +1,339 @@
+/// virtio MMIO 寄存器接口
+/// ref: https://github.com/rcore-os/virtio-drivers/blob/master/src/header.rs
+/// thanks!
+/// 虚拟设备直接挂在系统总线上
+use super::config::PAGE_SIZE;
+use bitflags::*;
+use volatile::{ReadOnly, Volatile, WriteOnly};
+
+/// MMIO Device Legacy Register Interface.
+///
+/// Ref: 4.2.4 Legacy interface
+#[repr(C)]
+#[derive(Debug)]
+pub struct VirtIOHeader {
+    /// Magic value
+    magic: ReadOnly<u32>,
+
+    /// Device version number
+    ///
+    /// Legacy device returns value 0x1.
+    /// 设备版本号
+    version: ReadOnly<u32>,
+
+    /// Virtio Subsystem Device ID
+    /// 子系统设备 ID
+    device_id: ReadOnly<u32>,
+
+    /// Virtio Subsystem Vendor ID
+    /// 子设备供应商 ID
+    vendor_id: ReadOnly<u32>,
+
+    /// Flags representing features the device supports
+    /// 设备支持的功能
+    device_features: ReadOnly<u32>,
+
+    /// Device (host) features word selection
+    /// 设备选择的功能
+    device_features_sel: WriteOnly<u32>,
+
+    /// Reserved
+    __r1: [ReadOnly<u32>; 2],
+
+    /// Flags representing device features understood and activated by the driver
+    /// 驱动程序理解的功能
+    driver_features: WriteOnly<u32>,
+
+    /// Activated (guest) features word selection
+    /// 驱动程序选择的设备功能
+    driver_features_sel: WriteOnly<u32>,
+
+    /// Guest page size
+    ///
+    /// The driver writes the guest page size in bytes to the register during
+    /// initialization, before any queues are used. This value should be a
+    /// power of 2 and is used by the device to calculate the Guest address
+    /// of the first queue page (see QueuePFN).
+    /// 操作系统内核中提供的页大小
+    guest_page_size: WriteOnly<u32>,
+
+    /// Reserved
+    __r2: ReadOnly<u32>,
+
+    /// Virtual queue index
+    ///
+    /// Writing to this register selects the virtual queue that the following
+    /// operations on the QueueNumMax, QueueNum, QueueAlign and QueuePFN
+    /// registers apply to. The index number of the first queue is zero (0x0).
+    /// 虚拟队列索引号
+    queue_sel: WriteOnly<u32>,
+
+    /// Maximum virtual queue size
+    ///
+    /// Reading from the register returns the maximum size of the queue the
+    /// device is ready to process or zero (0x0) if the queue is not available.
+    /// This applies to the queue selected by writing to QueueSel and is
+    /// allowed only when QueuePFN is set to zero (0x0), so when the queue is
+    /// not actively used.
+    /// 虚拟队列最大容量值，指虚拟队列的最大个数
+    queue_num_max: ReadOnly<u32>,
+
+    /// Virtual queue size
+    ///
+    /// Queue size is the number of elements in the queue. Writing to this
+    /// register notifies the device what size of the queue the driver will use.
+    /// This applies to the queue selected by writing to QueueSel.
+    /// 虚拟队列当前容量值，指虚拟队列当前的个数
+    queue_num: WriteOnly<u32>,
+
+    /// Used Ring alignment in the virtual queue
+    ///
+    /// Writing to this register notifies the device about alignment boundary
+    /// of the Used Ring in bytes. This value should be a power of 2 and
+    /// applies to the queue selected by writing to QueueSel.
+    /// 虚拟队列对齐边界，单位为字节
+    queue_align: WriteOnly<u32>,
+
+    /// Guest physical page number of the virtual queue
+    ///
+    /// Writing to this register notifies the device about location of the
+    /// virtual queue in the Guest’s physical address space. This value is
+    /// the index number of a page starting with the queue Descriptor Table.
+    /// Value zero (0x0) means physical address zero (0x00000000) and is illegal.
+    /// When the driver stops using the queue it writes zero (0x0) to this
+    /// register. Reading from this register returns the currently used page
+    /// number of the queue, therefore a value other than zero (0x0) means that
+    /// the queue is in use. Both read and write accesses apply to the queue
+    /// selected by writing to QueueSel.
+    /// 虚拟队列所在物理页号
+    queue_pfn: Volatile<u32>,
+
+    /// new interface only
+    queue_ready: Volatile<u32>,
+
+    /// Reserved
+    __r3: [ReadOnly<u32>; 2],
+
+    /// Queue notifier
+    /// 队列通知
+    queue_notify: WriteOnly<u32>,
+
+    /// Reserved
+    __r4: [ReadOnly<u32>; 3],
+
+    /// Interrupt status
+    /// 中断状态
+    interrupt_status: ReadOnly<u32>,
+
+    /// Interrupt acknowledge
+    /// 中断确认
+    interrupt_ack: WriteOnly<u32>,
+
+    /// Reserved
+    __r5: [ReadOnly<u32>; 2],
+
+    /// Device status
+    ///
+    /// Reading from this register returns the current device status flags.
+    /// Writing non-zero values to this register sets the status flags,
+    /// indicating the OS/driver progress. Writing zero (0x0) to this register
+    /// triggers a device reset. The device sets QueuePFN to zero (0x0) for
+    /// all queues in the device. Also see 3.1 Device Initialization.
+    /// 设备状态
+    status: Volatile<DeviceStatus>,
+
+    /// Reserved
+    __r6: [ReadOnly<u32>; 3],
+
+    // new interface only since here
+    queue_desc_low: WriteOnly<u32>,
+    queue_desc_high: WriteOnly<u32>,
+
+    /// Reserved
+    __r7: [ReadOnly<u32>; 2],
+
+    queue_avail_low: WriteOnly<u32>,
+    queue_avail_high: WriteOnly<u32>,
+
+    /// Reserved
+    __r8: [ReadOnly<u32>; 2],
+
+    queue_used_low: WriteOnly<u32>,
+    queue_used_high: WriteOnly<u32>,
+
+    /// Reserved
+    __r9: [ReadOnly<u32>; 21],
+
+    // 配置空间
+    config_generation: ReadOnly<u32>,
+}
+
+impl VirtIOHeader {
+    /// Verify a valid header.
+    pub fn verify(&self) -> bool {
+        self.magic.read() == 0x7472_6976 && self.version.read() == 1 && self.device_id.read() != 0
+    }
+
+    /// Get the device type.
+    pub fn device_type(&self) -> DeviceType {
+        match self.device_id.read() {
+            x @ 1..=13 | x @ 16..=24 => unsafe { core::mem::transmute(x as u8) },
+            _ => DeviceType::Invalid,
+        }
+    }
+
+    /// Get the vendor ID.
+    pub fn vendor_id(&self) -> u32 {
+        self.vendor_id.read()
+    }
+
+    /// Begin initializing the device.
+    ///
+    /// Ref: virtio 3.1.1 Device Initialization
+    pub fn begin_init(&mut self, negotiate_features: impl FnOnce(u64) -> u64) {
+        // 设置设备状态位
+        self.status.write(DeviceStatus::ACKNOWLEDGE);
+        self.status.write(DeviceStatus::DRIVER);
+
+        // 对 features 进行谈判
+        let features = self.read_device_features();
+        self.write_driver_features(negotiate_features(features));
+        self.status.write(DeviceStatus::FEATURES_OK);
+
+        self.guest_page_size.write(PAGE_SIZE as u32);
+    }
+
+    /// Finish initializing the device.
+    pub fn finish_init(&mut self) {
+        self.status.write(DeviceStatus::DRIVER_OK);
+    }
+
+    /// Read device features.
+    fn read_device_features(&mut self) -> u64 {
+        self.device_features_sel.write(0); // device features [0, 32)
+        let mut device_features_bits = self.device_features.read().into();
+        self.device_features_sel.write(1); // device features [32, 64)
+        device_features_bits += (self.device_features.read() as u64) << 32;
+        device_features_bits
+    }
+
+    /// Write device features.
+    fn write_driver_features(&mut self, driver_features: u64) {
+        self.driver_features_sel.write(0); // driver features [0, 32)
+        self.driver_features.write(driver_features as u32);
+        self.driver_features_sel.write(1); // driver features [32, 64)
+        self.driver_features.write((driver_features >> 32) as u32);
+    }
+
+    /// Set queue.
+    pub fn queue_set(&mut self, queue: u32, size: u32, align: u32, pfn: u32) {
+        self.queue_sel.write(queue);
+        self.queue_num.write(size);
+        self.queue_align.write(align);
+        self.queue_pfn.write(pfn);
+    }
+
+    /// Get guest physical page number of the virtual queue.
+    pub fn queue_physical_page_number(&mut self, queue: u32) -> u32 {
+        self.queue_sel.write(queue);
+        self.queue_pfn.read()
+    }
+
+    /// Whether the queue is in used.
+    pub fn queue_used(&mut self, queue: u32) -> bool {
+        self.queue_physical_page_number(queue) != 0
+    }
+
+    /// Get the max size of queue.
+    pub fn max_queue_size(&self) -> u32 {
+        self.queue_num_max.read()
+    }
+
+    /// Notify device.
+    /// 参数 queue 表示通知的队列编号
+    pub fn notify(&mut self, queue: u32) {
+        self.queue_notify.write(queue);
+    }
+
+    /// Acknowledge interrupt and return true if success.
+    pub fn ack_interrupt(&mut self) -> bool {
+        let interrupt = self.interrupt_status.read();
+        if interrupt != 0 {
+            self.interrupt_ack.write(interrupt);
+            true
+        } else {
+            false
+        }
+    }
+
+    /// 返回中断状态
+    pub fn interrupt_status(&self) -> u32 {
+        self.interrupt_status.read()
+    }
+
+    /// Get the pointer to config space (at offset 0x100)
+    pub fn config_space(&self) -> *mut u64 {
+        (self as *const _ as usize + CONFIG_SPACE_OFFSET) as _
+    }
+}
+
+bitflags! {
+    /// The device status field.
+    struct DeviceStatus: u32 {
+        /// Indicates that the guest OS has found the device and recognized it
+        /// as a valid virtio device.
+        const ACKNOWLEDGE = 1;
+
+        /// Indicates that the guest OS knows how to drive the device.
+        const DRIVER = 2;
+
+        /// Indicates that something went wrong in the guest, and it has given
+        /// up on the device. This could be an internal error, or the driver
+        /// didn’t like the device for some reason, or even a fatal error
+        /// during device operation.
+        const FAILED = 128;
+
+        /// Indicates that the driver has acknowledged all the features it
+        /// understands, and feature negotiation is complete.
+        const FEATURES_OK = 8;
+
+        /// Indicates that the driver is set up and ready to drive the device.
+        const DRIVER_OK = 4;
+
+        /// Indicates that the device has experienced an error from which it
+        /// can’t recover.
+        const DEVICE_NEEDS_RESET = 64;
+    }
+}
+
+const CONFIG_SPACE_OFFSET: usize = 0x100;
+
+/// Types of virtio devices.
+#[repr(u8)]
+#[derive(Debug, Eq, PartialEq)]
+#[allow(missing_docs)]
+pub enum DeviceType {
+    Invalid = 0,
+    Network = 1,
+    Block = 2,
+    Console = 3,
+    EntropySource = 4,
+    MemoryBallooning = 5,
+    IoMemory = 6,
+    Rpmsg = 7,
+    ScsiHost = 8,
+    _9P = 9,
+    Mac80211 = 10,
+    RprocSerial = 11,
+    VirtioCAIF = 12,
+    MemoryBalloon = 13,
+    GPU = 16,
+    Timer = 17,
+    Input = 18,
+    Socket = 19,
+    Crypto = 20,
+    SignalDistributionModule = 21,
+    Pstore = 22,
+    IOMMU = 23,
+    Memory = 24,
+}
diff --git a/async_tiny/async_virtio_driver/src/queue.rs b/async_tiny/async_virtio_driver/src/queue.rs
new file mode 100644
index 0000000..93bcc9f
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/queue.rs
@@ -0,0 +1,451 @@
+use super::config::*;
+use super::dma::DMA;
+use super::mmio::VirtIOHeader;
+use super::*;
+use crate::util::align_up_page;
+use alloc::vec::Vec;
+use bitflags::bitflags;
+use core::ptr::NonNull;
+use core::{
+    mem::size_of,
+    sync::atomic::{fence, Ordering},
+};
+/// 虚拟队列相关实现
+/// ref: https://github.com/rcore-os/virtio-drivers/blob/master/src/queue.rs
+/// thanks!
+use volatile::Volatile;
+
+type AvailableRing = Ring<Volatile<u16>>;
+type UsedRing = Ring<UsedElement>;
+
+/// Virtio 中的虚拟队列接口，前后端通信的桥梁
+///
+#[repr(C)]
+pub struct VirtQueue {
+    /// DMA 空间
+    dma: DMA,
+    /// 描述符表
+    descriptor_table: NonNull<[Descriptor]>,
+    /// 可用环
+    avail_ring: NonNull<AvailableRing>,
+    /// 已用环
+    used_ring: NonNull<UsedRing>,
+    /// 虚拟队列索引值
+    /// 一个虚拟设备实现可能有多个虚拟队列
+    queue_index: u32,
+    /// 虚拟队列长度
+    /// 等于描述符表中条目的数量
+    queue_size: u16,
+    /// 已经使用的描述符数目
+    used_num: u16,
+    /// 空闲描述符链表头
+    /// 初始时所有描述符通过 next 指针依次相连形成空闲链表
+    free_desc_head: u16,
+    /// 可用环的索引值
+    avail_index: u16,
+    /// 设备上次已取的已用环元素的位置
+    last_used_index: u16,
+}
+
+// 跨上下文递交所有权，结构体意义不变，可以 Send
+unsafe impl Send for VirtQueue {}
+// 可以跨上下文递交引用，也可以 Sync
+unsafe impl Sync for VirtQueue {}
+
+impl VirtQueue {
+    pub fn new(header: &mut VirtIOHeader, index: usize, size: u16) -> Result<Self> {
+        if header.queue_used(index as u32) {
+            return Err(VirtIOError::QueueInUsed(index));
+        }
+        if !size.is_power_of_two() || header.max_queue_size() < size as u32 {
+            return Err(VirtIOError::InvalidParameter);
+        }
+        let queue_layout = VirtQueueMemLayout::new(size);
+        let dma = DMA::new(queue_layout.mem_size / PAGE_SIZE)?;
+        println!("[virtio] DMA address: {:#x}", dma.start_physical_address());
+
+        // 在 MMIO 接口中设置虚拟队列的相关信息
+        header.queue_set(
+            index as u32,
+            size as u32,
+            PAGE_SIZE as u32,
+            dma.ppn() as u32,
+        );
+
+        // 描述符表起始地址
+        let desc_table = unsafe {
+            core::slice::from_raw_parts_mut(
+                dma.start_virtual_address() as *mut Descriptor,
+                size as usize,
+            )
+        };
+
+        // 将空描述符连成链表
+        for i in 0..(size - 1) {
+            desc_table[i as usize].next.write(i + 1);
+        }
+
+        let descriptor_table = NonNull::new(desc_table).unwrap();
+        let avail_ring = NonNull::new(unsafe {
+            &mut *((dma.start_virtual_address() + queue_layout.avail_ring_offset)
+                as *mut AvailableRing)
+        })
+        .unwrap();
+        let used_ring = NonNull::new(unsafe {
+            &mut *((dma.start_virtual_address() + queue_layout.used_ring_offset) as *mut UsedRing)
+        })
+        .unwrap();
+
+        Ok(VirtQueue {
+            dma,
+            descriptor_table,
+            avail_ring,
+            used_ring,
+            queue_size: size,
+            queue_index: index as u32,
+            used_num: 0,
+            free_desc_head: 0,
+            avail_index: 0,
+            last_used_index: 0,
+        })
+    }
+
+    pub async fn async_new(
+        header: &mut VirtIOHeader,
+        index: usize,
+        size: u16,
+    ) -> Result<VirtQueue> {
+        if header.queue_used(index as u32) {
+            return Err(VirtIOError::QueueInUsed(index));
+        }
+        if !size.is_power_of_two() || header.max_queue_size() < size as u32 {
+            return Err(VirtIOError::InvalidParameter);
+        }
+        let queue_layout = VirtQueueMemLayout::new(size);
+        let dma = DMA::alloc(queue_layout.mem_size / PAGE_SIZE).await;
+        println!("[virtio] DMA address: {:#x}", dma.start_physical_address());
+
+        // 在 MMIO 接口中设置虚拟队列的相关信息
+        header.queue_set(
+            index as u32,
+            size as u32,
+            PAGE_SIZE as u32,
+            dma.ppn() as u32,
+        );
+
+        // 描述符表起始地址
+        let desc_table = unsafe {
+            core::slice::from_raw_parts_mut(
+                dma.start_virtual_address() as *mut Descriptor,
+                size as usize,
+            )
+        };
+
+        // 将空描述符连成链表
+        for i in 0..(size - 1) {
+            desc_table[i as usize].next.write(i + 1);
+        }
+
+        let descriptor_table = NonNull::new(desc_table).unwrap();
+        let avail_ring = NonNull::new(unsafe {
+            &mut *((dma.start_virtual_address() + queue_layout.avail_ring_offset)
+                as *mut AvailableRing)
+        })
+        .unwrap();
+        let used_ring = NonNull::new(unsafe {
+            &mut *((dma.start_virtual_address() + queue_layout.used_ring_offset) as *mut UsedRing)
+        })
+        .unwrap();
+
+        Ok(VirtQueue {
+            dma,
+            descriptor_table,
+            avail_ring,
+            used_ring,
+            queue_size: size,
+            queue_index: index as u32,
+            used_num: 0,
+            free_desc_head: 0,
+            avail_index: 0,
+            last_used_index: 0,
+        })
+    }
+
+    /// 添加 buffers 到虚拟队列，返回一个 token
+    pub fn add_buf(&mut self, inputs: &[&[u8]], outputs: &[&mut [u8]]) -> Result<u16> {
+        if inputs.is_empty() && outputs.is_empty() {
+            return Err(VirtIOError::InvalidParameter);
+        }
+        if inputs.len() + outputs.len() + self.used_num as usize > self.queue_size as usize {
+            // buffer 数量溢出
+            return Err(VirtIOError::Overflow);
+        }
+
+        // 从空闲描述符表中分配描述符
+        let head = self.free_desc_head;
+        let mut tail = self.free_desc_head;
+        let mut next_free_desc_head = self.free_desc_head;
+        let descriptor_table = unsafe { self.descriptor_table.as_mut() };
+        // 将输入缓冲区的信息写入描述符表
+        inputs.iter().for_each(|input| {
+            let desc = &mut descriptor_table[next_free_desc_head as usize];
+            // 将 buffer 的信息写入描述符
+            desc.set_buf(input);
+            // 设置描述符的标识位
+            desc.flags.write(DescriptorFlags::NEXT);
+            tail = next_free_desc_head;
+            next_free_desc_head = desc.next.read();
+        });
+        // 更新空闲描述符表头部
+        self.free_desc_head = next_free_desc_head;
+        // 将输出缓冲区的信息写入描述符表
+        outputs.iter().for_each(|output| {
+            let desc = &mut descriptor_table[next_free_desc_head as usize];
+            desc.set_buf(output);
+            desc.flags
+                .write(DescriptorFlags::NEXT | DescriptorFlags::WRITE);
+            tail = next_free_desc_head;
+            next_free_desc_head = desc.next.read();
+        });
+        // 更新空闲描述符表头部
+        self.free_desc_head = next_free_desc_head;
+        // 清除描述符链的最后一个元素的 next 指针
+        {
+            let desc = &mut descriptor_table[tail as usize];
+            let mut flags = desc.flags.read();
+            flags.remove(DescriptorFlags::NEXT);
+            desc.flags.write(flags);
+        }
+        // 更新已使用描述符数目
+        self.used_num += (inputs.len() + outputs.len()) as u16;
+
+        // 将描述符链的头部放入可用环中
+        let avail_ring = unsafe { self.avail_ring.as_mut() };
+        let avail_slot = self.avail_index & (self.queue_size - 1);
+        avail_ring.ring[avail_slot as usize].write(head);
+
+        // write barrier(内存屏障操作？)
+        fence(Ordering::SeqCst);
+
+        // 更新可用环的头部
+        self.avail_index = self.avail_index.wrapping_add(1);
+        avail_ring.idx.write(self.avail_index);
+        Ok(head)
+    }
+
+    /// 是否可以从可用环中弹出没处理的项
+    pub fn can_pop(&self) -> bool {
+        let used_ring = unsafe { self.used_ring.as_ref() };
+        self.last_used_index != used_ring.idx.read()
+    }
+
+    /// 可用的空闲描述符数量
+    pub fn free_desc_num(&self) -> usize {
+        (self.queue_size - self.used_num) as usize
+    }
+
+    /// 回收描述符
+    /// 该方法将会把需要回收的描述符链放到空闲描述符链的头部
+    fn recycle_descriptors(&mut self, mut head: u16) {
+        let origin_desc_head = self.free_desc_head;
+        self.free_desc_head = head;
+        let descriptor_table = unsafe { self.descriptor_table.as_mut() };
+        loop {
+            let desc = &mut descriptor_table[head as usize];
+            let flags = desc.flags.read();
+            if flags.contains(DescriptorFlags::NEXT) {
+                head = desc.next.read();
+                self.used_num -= 1;
+            } else {
+                desc.next.write(origin_desc_head);
+                self.used_num -= 1;
+                return;
+            }
+        }
+    }
+
+    /// 从已用环中弹出一个 token，并返回长度
+    /// ref: linux virtio_ring.c virtqueue_get_buf_ctx
+    pub fn pop_used(&mut self) -> Result<(u16, u32)> {
+        if !self.can_pop() {
+            return Err(VirtIOError::UsedRingNotReady);
+        }
+        // read barrier
+        fence(Ordering::SeqCst);
+
+        let used_ring = unsafe { self.used_ring.as_mut() };
+        let last_used_slot = self.last_used_index & (self.queue_size - 1);
+        let index = used_ring.ring[last_used_slot as usize].id.read() as u16;
+        let len = used_ring.ring[last_used_slot as usize].len.read();
+
+        self.recycle_descriptors(index);
+        self.last_used_index = self.last_used_index.wrapping_add(1);
+
+        Ok((index, len))
+    }
+
+    /// 从已用环中取出下一个 token，但不弹出
+    pub fn next_used(&self) -> Result<(u16, u32)> {
+        if !self.can_pop() {
+            return Err(VirtIOError::UsedRingNotReady);
+        }
+
+        // read barrier
+        fence(Ordering::SeqCst);
+
+        let used_ring = unsafe { self.used_ring.as_ref() };
+        let last_used_slot = self.last_used_index & (self.queue_size - 1);
+        let index = used_ring.ring[last_used_slot as usize].id.read() as u16;
+        let len = used_ring.ring[last_used_slot as usize].len.read();
+
+        Ok((index, len))
+    }
+
+    pub fn free_head(&self) -> u16 {
+        self.free_desc_head
+    }
+
+    pub fn descriptor(&self, index: usize) -> Descriptor {
+        unsafe { self.descriptor_table.as_ref()[index].clone() }
+    }
+
+    pub fn desc_table(&self) -> &[Descriptor] {
+        unsafe { self.descriptor_table.as_ref() }
+    }
+
+    pub fn desc_table_mut(&mut self) -> &mut [Descriptor] {
+        unsafe { self.descriptor_table.as_mut() }
+    }
+
+    pub fn avail_ring(&self) -> &AvailableRing {
+        unsafe { self.avail_ring.as_ref() }
+    }
+
+    pub fn avail_ring_mut(&mut self) -> &mut AvailableRing {
+        unsafe { self.avail_ring.as_mut() }
+    }
+
+    pub fn used_ring(&self) -> &UsedRing {
+        unsafe { self.used_ring.as_ref() }
+    }
+
+    pub fn used_ring_mut(&mut self) -> &mut UsedRing {
+        unsafe { self.used_ring.as_mut() }
+    }
+
+    /// 返回给定头部的描述符链
+    pub fn descriptor_link(&self, head: u16) -> Vec<&Descriptor> {
+        let desc_table = self.desc_table();
+        let mut ret = Vec::new();
+        let mut pos = head;
+        while desc_table[pos as usize]
+            .flags
+            .read()
+            .contains(DescriptorFlags::NEXT)
+        {
+            let desc = &desc_table[pos as usize];
+            ret.push(desc);
+            pos = desc.next.read();
+        }
+        // last one
+        ret.push(&desc_table[pos as usize]);
+        ret
+    }
+}
+
+/// 虚拟队列内存布局信息
+struct VirtQueueMemLayout {
+    /// 可用环地址偏移
+    avail_ring_offset: usize,
+    /// 已用环地址偏移
+    used_ring_offset: usize,
+    /// 总大小
+    mem_size: usize,
+}
+
+impl VirtQueueMemLayout {
+    fn new(queue_size: u16) -> Self {
+        assert!(
+            queue_size.is_power_of_two(),
+            "[virtio] queue size must be a power off 2"
+        );
+        let q_size = queue_size as usize;
+        let descriptors_size = size_of::<Descriptor>() * q_size;
+        let avail_ring_size = size_of::<u16>() * (3 + q_size);
+        let used_ring_size = size_of::<u16>() * 3 + size_of::<UsedElement>() * q_size;
+        VirtQueueMemLayout {
+            avail_ring_offset: descriptors_size,
+            used_ring_offset: align_up_page(descriptors_size + avail_ring_size),
+            mem_size: align_up_page(descriptors_size + avail_ring_size)
+                + align_up_page(used_ring_size),
+        }
+    }
+}
+
+/// 描述符
+#[repr(C, align(16))]
+#[derive(Debug)]
+pub struct Descriptor {
+    /// buffer 的物理地址
+    pub paddr: Volatile<u64>,
+    /// buffer 的长度
+    len: Volatile<u32>,
+    /// 标识
+    flags: Volatile<DescriptorFlags>,
+    /// 下一个描述符的指针
+    next: Volatile<u16>,
+}
+
+impl Clone for Descriptor {
+    fn clone(&self) -> Self {
+        Self {
+            paddr: Volatile::<u64>::new(self.paddr.read()),
+            len: Volatile::<u32>::new(self.len.read()),
+            flags: Volatile::<DescriptorFlags>::new(self.flags.read()),
+            next: Volatile::<u16>::new(self.next.read()),
+        }
+    }
+}
+
+impl Descriptor {
+    /// 把特定 buffer 的信息写入到描述符
+    fn set_buf(&mut self, buf: &[u8]) {
+        let buf_paddr = unsafe { virtio_virt_to_phys(buf.as_ptr() as usize) as u64 };
+        self.paddr.write(buf_paddr);
+        self.len.write(buf.len() as u32);
+    }
+}
+
+bitflags! {
+    /// 描述符的标识
+    struct DescriptorFlags: u16 {
+        const NEXT = 1;
+        const WRITE = 2;
+        const INDIRECT = 4;
+    }
+}
+
+/// 环
+/// 通过泛型对可用环和已用环进行统一抽象
+#[repr(C)]
+#[derive(Debug)]
+pub struct Ring<Entry: Sized> {
+    /// 与通知机制相关
+    flags: Volatile<u16>,
+    idx: Volatile<u16>,
+    pub ring: [Entry; VIRT_QUEUE_SIZE],
+    // unused
+    event: Volatile<u16>,
+}
+
+/// 已用环中的项
+#[repr(C)]
+#[derive(Debug)]
+pub struct UsedElement {
+    id: Volatile<u32>,
+    len: Volatile<u32>,
+}
+
+extern "C" {
+    fn virtio_virt_to_phys(vaddr: usize) -> usize;
+}
diff --git a/async_tiny/async_virtio_driver/src/sbi.rs b/async_tiny/async_virtio_driver/src/sbi.rs
new file mode 100644
index 0000000..f3b5f26
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/sbi.rs
@@ -0,0 +1,69 @@
+/// @title: `sbi_call`
+/// @author: Andre
+/// @date: 2022-11-04
+/// ```
+/// fn sbi_call(which: usize, arg0: usize, arg1: usize, arg2: usize) -> usize {
+///     let ret;
+///     unsafe {
+///         llvm_asm!("ecall"
+///             : "={x10}" (ret)
+///             : "{x10}" (arg0), "{x11}" (arg1), "{x12}" (arg2), "{x17}" (which)
+///             : "memory"
+///             : "volatile");
+///     }
+///     ret
+/// }
+/// ```
+#[inline(always)]
+fn sbi_call(which: usize, arg0: usize, arg1: usize, arg2: usize) -> usize {
+    let mut ret;
+    unsafe {
+        core::arch::asm!(
+            "li x16, 0",
+            "ecall",
+            inlateout("x10") arg0 => ret,
+            in("x11") arg1,
+            in("x12") arg2,
+            in("x17") which,
+        );
+    }
+    ret
+}
+#[allow(unused)]
+const SBI_SET_TIMER: usize = 0;
+#[allow(unused)]
+const SBI_CONSOLE_PUTCHAR: usize = 1;
+#[allow(unused)]
+const SBI_CONSOLE_GETCHAR: usize = 2;
+#[allow(unused)]
+const SBI_CLEAR_IPI: usize = 3;
+#[allow(unused)]
+const SBI_SEND_IPI: usize = 4;
+#[allow(unused)]
+const SBI_REMOTE_FENCE_I: usize = 5;
+#[allow(unused)]
+const SBI_REMOTE_SFENCE_VMA: usize = 6;
+#[allow(unused)]
+const SBI_REMOTE_SFENCE_VMA_ASID: usize = 7;
+#[allow(unused)]
+const SBI_SHUTDOWN: usize = 8;
+
+pub fn console_putchar(c: usize) {
+    sbi_call(SBI_CONSOLE_PUTCHAR, c, 0, 0);
+}
+
+#[allow(unused)]
+pub fn console_getchar() -> usize {
+    sbi_call(SBI_CONSOLE_GETCHAR, 0, 0, 0)
+}
+
+#[allow(unused)]
+pub fn shutdown() -> ! {
+    sbi_call(SBI_SHUTDOWN, 0, 0, 0);
+    unreachable!()
+}
+
+#[allow(unused)]
+pub fn set_timer(time: usize) {
+    sbi_call(SBI_SET_TIMER, time, 0, 0);
+}
diff --git a/async_tiny/async_virtio_driver/src/util.rs b/async_tiny/async_virtio_driver/src/util.rs
new file mode 100644
index 0000000..b906bc8
--- /dev/null
+++ b/async_tiny/async_virtio_driver/src/util.rs
@@ -0,0 +1,25 @@
+use super::config::*;
+
+/// 向上对齐页大小
+pub const fn align_up_page(size: usize) -> usize {
+    (size + PAGE_SIZE) & !(PAGE_SIZE - 1)
+}
+
+/// todo
+#[allow(unused)]
+pub const fn pages(size: usize) -> usize {
+    (size + PAGE_SIZE - 1) / PAGE_SIZE
+}
+
+/// 将一个结构体转换成缓冲区
+/// 不安全
+pub unsafe trait AsBuf: Sized {
+    fn as_buf(&self) -> &[u8] {
+        unsafe { core::slice::from_raw_parts(self as *const _ as _, core::mem::size_of::<Self>()) }
+    }
+    fn as_buf_mut(&mut self) -> &mut [u8] {
+        unsafe {
+            core::slice::from_raw_parts_mut(self as *mut _ as _, core::mem::size_of::<Self>())
+        }
+    }
+}
-- 
2.34.1

